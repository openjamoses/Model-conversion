{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPih/AMBuymuP61mSZCcH1T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/openjamoses/Model-conversion/blob/main/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzNoTBRfvvxj"
      },
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-KXCJHQwBw7"
      },
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(256, 120)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.relu4(y)\n",
        "        y = self.fc3(y)\n",
        "        y = self.relu5(y)\n",
        "        return y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65qtYNvczdVn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from torchvision.datasets import mnist\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ZfQwvs0lIR",
        "outputId": "3553b760-3ff9-4b36-ea67-a61542bfa7e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcUfbVD7zdlu"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/dataset/MNIST'\n",
        "batch_size = 256\n",
        "train_dataset = mnist.MNIST(root='/content/drive/MyDrive/Colab Notebooks/dataset/MNIST/train', train=True, transform=ToTensor())\n",
        "test_dataset = mnist.MNIST(root=data_path+'/test', train=False, transform=ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "model = Model()\n",
        "sgd = SGD(model.parameters(), lr=1e-1)\n",
        "cost = CrossEntropyLoss()\n",
        "epoch = 10  \n",
        "\n",
        "model_name = 'lenet'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEviuCMqtmE"
      },
      "source": [
        "def train(model, num_epochs):\n",
        "  since = time.time()\n",
        "  date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "\n",
        "  data_file = open('/content/exp_train_{}_{}.csv'.format(model_name, date), mode='w+', newline='', encoding='utf-8')\n",
        "  data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  data_writer.writerow(['Model','Epoch','Train_loss', 'Train_acc','Val_loss', 'Val_acc', 'time','Elapse_time','date'])\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  #best_acc = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "    since_1 = time.time()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    _sum = 0\n",
        "    since_1 = time.time()\n",
        "    for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "        label_np = np.zeros((train_label.shape[0], 10))\n",
        "        sgd.zero_grad()\n",
        "        predict_y = model(train_x.float())\n",
        "        loss = cost(predict_y, train_label.long())\n",
        "        if idx % 10 == 0:\n",
        "            print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
        "\n",
        "        running_loss += loss.sum().item()\n",
        "        predict_y = model(train_x.float()).detach()\n",
        "        predict_ys = np.argmax(predict_y, axis=-1)\n",
        "        label_np = train_label.numpy()\n",
        "        _ = predict_ys == train_label\n",
        "        running_corrects += np.sum(_.numpy(), axis=-1)\n",
        "        _sum += _.shape[0]\n",
        "\n",
        "        loss.backward()\n",
        "        sgd.step()\n",
        "    epoch_loss = running_loss / _sum\n",
        "    epoch_acc = running_corrects / _sum\n",
        "    \n",
        "    \n",
        "    #rows.append('{:.4f}'.format(epoch_loss))\n",
        "    #rows.append('{:.4f}'.format(epoch_acc))\n",
        "\n",
        "\n",
        "    correct = 0\n",
        "    running_loss2 = 0.0\n",
        "    _sum2 = 0\n",
        "\n",
        "    for idx, (test_x, test_label) in enumerate(test_loader):\n",
        "        \n",
        "        predict_y = model(test_x.float())\n",
        "        loss = cost(predict_y, test_label.long())\n",
        "        predict_y = model(test_x.float()).detach()\n",
        "        predict_ys = np.argmax(predict_y, axis=-1)\n",
        "        label_np = test_label.numpy()\n",
        "        _ = predict_ys == test_label\n",
        "        correct += np.sum(_.numpy(), axis=-1)\n",
        "        _sum2 += _.shape[0]\n",
        "        running_loss2 += loss.sum().item()\n",
        "        #loss.backward()\n",
        "\n",
        "    epoch_loss2 = running_loss2 / _sum2\n",
        "    epoch_acc2 = correct / _sum2\n",
        "    print('accuracy: {:.2f}'.format(correct / _sum2))\n",
        "    print('{} TrainLoss: {:.4f} TrainAcc: {:.4f}, ValLoss: {:.4f}, ValAcc: {:.4f}'.format(\n",
        "                epoch, epoch_loss, epoch_acc, epoch_loss2, epoch_acc2))\n",
        "    time_elapsed_1 = time.time() - since_1\n",
        "    rows = [model_name, epoch, '{:.4f}'.format(epoch_loss), '{:.4f}'.format(epoch_acc),'{:.4f}'.format(epoch_loss2), '{:.4f}'.format(epoch_acc2), time.time(), \n",
        "            '{:.0f}m {:.0f}s'.format(time_elapsed_1 // 60, time_elapsed_1 % 60), date]\n",
        "    data_writer.writerow(rows)\n",
        "    val = correct / _sum\n",
        "    if val > best_acc:\n",
        "      model_best = model\n",
        "      best_acc = val\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    #torch.save(model, '/content/mnist_{:.2f}.pkl'.format(correct / _sum))\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  data_writer.writerow(['','', 'Best val Acc: {:4f}'.format(best_acc), time.time(),'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),''])\n",
        "\n",
        "  data_file.close()\n",
        "  return model "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPgiYAZx1uGU",
        "outputId": "19f6fd01-b0a6-4fd9-d72b-f813b3a624cc"
      },
      "source": [
        "model_ft = train(model,epoch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "idx: 0, loss: 1.0049935579299927\n",
            "idx: 10, loss: 1.016793966293335\n",
            "idx: 20, loss: 0.9878928065299988\n",
            "idx: 30, loss: 0.9526361227035522\n",
            "idx: 40, loss: 0.94521164894104\n",
            "idx: 50, loss: 1.0548840761184692\n",
            "idx: 60, loss: 0.9801884889602661\n",
            "idx: 70, loss: 0.9798109531402588\n",
            "idx: 80, loss: 1.0301663875579834\n",
            "idx: 90, loss: 0.920755922794342\n",
            "idx: 100, loss: 0.9329324960708618\n",
            "idx: 110, loss: 0.9540637731552124\n",
            "idx: 120, loss: 1.0282750129699707\n",
            "idx: 130, loss: 0.9340881705284119\n",
            "idx: 140, loss: 1.0027700662612915\n",
            "idx: 150, loss: 0.8090428113937378\n",
            "idx: 160, loss: 0.8769623041152954\n",
            "idx: 170, loss: 0.8618240356445312\n",
            "idx: 180, loss: 1.075975775718689\n",
            "idx: 190, loss: 0.9355840086936951\n",
            "idx: 200, loss: 0.9106934666633606\n",
            "idx: 210, loss: 0.8904879689216614\n",
            "idx: 220, loss: 0.9498329758644104\n",
            "idx: 230, loss: 0.9810305237770081\n",
            "accuracy: 0.58\n",
            "0 TrainLoss: 0.0038 TrainAcc: 0.5902, ValLoss: 0.0039, ValAcc: 0.5850\n",
            "Epoch 1/9\n",
            "----------\n",
            "idx: 0, loss: 1.001354694366455\n",
            "idx: 10, loss: 1.0121827125549316\n",
            "idx: 20, loss: 0.9820271134376526\n",
            "idx: 30, loss: 0.9491692781448364\n",
            "idx: 40, loss: 0.9451094269752502\n",
            "idx: 50, loss: 1.0525846481323242\n",
            "idx: 60, loss: 0.9788928031921387\n",
            "idx: 70, loss: 0.9786168932914734\n",
            "idx: 80, loss: 1.0287810564041138\n",
            "idx: 90, loss: 0.9190866947174072\n",
            "idx: 100, loss: 0.9296999573707581\n",
            "idx: 110, loss: 0.9521113634109497\n",
            "idx: 120, loss: 1.0270699262619019\n",
            "idx: 130, loss: 0.929449200630188\n",
            "idx: 140, loss: 1.0014070272445679\n",
            "idx: 150, loss: 0.8085103631019592\n",
            "idx: 160, loss: 0.8756427764892578\n",
            "idx: 170, loss: 0.8621730208396912\n",
            "idx: 180, loss: 1.0714441537857056\n",
            "idx: 190, loss: 0.9319742918014526\n",
            "idx: 200, loss: 0.9081200361251831\n",
            "idx: 210, loss: 0.8895261883735657\n",
            "idx: 220, loss: 0.9467496871948242\n",
            "idx: 230, loss: 0.9810047745704651\n",
            "accuracy: 0.58\n",
            "1 TrainLoss: 0.0038 TrainAcc: 0.5908, ValLoss: 0.0039, ValAcc: 0.5850\n",
            "Epoch 2/9\n",
            "----------\n",
            "idx: 0, loss: 0.9954860210418701\n",
            "idx: 10, loss: 1.0069973468780518\n",
            "idx: 20, loss: 0.9784115552902222\n",
            "idx: 30, loss: 0.947730302810669\n",
            "idx: 40, loss: 0.948100745677948\n",
            "idx: 50, loss: 1.0500668287277222\n",
            "idx: 60, loss: 0.9791886806488037\n",
            "idx: 70, loss: 0.9782475829124451\n",
            "idx: 80, loss: 1.0262256860733032\n",
            "idx: 90, loss: 0.9188716411590576\n",
            "idx: 100, loss: 0.925057053565979\n",
            "idx: 110, loss: 0.9507953524589539\n",
            "idx: 120, loss: 1.0250003337860107\n",
            "idx: 130, loss: 0.9263518452644348\n",
            "idx: 140, loss: 1.0001108646392822\n",
            "idx: 150, loss: 0.8079875111579895\n",
            "idx: 160, loss: 0.8746994733810425\n",
            "idx: 170, loss: 0.861404538154602\n",
            "idx: 180, loss: 1.0666723251342773\n",
            "idx: 190, loss: 0.9309595227241516\n",
            "idx: 200, loss: 0.9068291187286377\n",
            "idx: 210, loss: 0.8897240161895752\n",
            "idx: 220, loss: 0.9449816346168518\n",
            "idx: 230, loss: 0.9808554649353027\n",
            "accuracy: 0.58\n",
            "2 TrainLoss: 0.0037 TrainAcc: 0.5911, ValLoss: 0.0039, ValAcc: 0.5850\n",
            "Epoch 3/9\n",
            "----------\n",
            "idx: 0, loss: 0.9915907979011536\n",
            "idx: 10, loss: 1.0045406818389893\n",
            "idx: 20, loss: 0.9760401844978333\n",
            "idx: 30, loss: 0.94624924659729\n",
            "idx: 40, loss: 0.94517582654953\n",
            "idx: 50, loss: 1.0483793020248413\n",
            "idx: 60, loss: 0.9789087772369385\n",
            "idx: 70, loss: 0.9783608913421631\n",
            "idx: 80, loss: 1.024248480796814\n",
            "idx: 90, loss: 0.9180377125740051\n",
            "idx: 100, loss: 0.9198141694068909\n",
            "idx: 110, loss: 0.9478397965431213\n",
            "idx: 120, loss: 1.0242815017700195\n",
            "idx: 130, loss: 0.9233773946762085\n",
            "idx: 140, loss: 0.9988391399383545\n",
            "idx: 150, loss: 0.8067933917045593\n",
            "idx: 160, loss: 0.8742080926895142\n",
            "idx: 170, loss: 0.8615256547927856\n",
            "idx: 180, loss: 1.0645300149917603\n",
            "idx: 190, loss: 0.9281256198883057\n",
            "idx: 200, loss: 0.9056226015090942\n",
            "idx: 210, loss: 0.8896662592887878\n",
            "idx: 220, loss: 0.9436468482017517\n",
            "idx: 230, loss: 0.9807722568511963\n",
            "accuracy: 0.58\n",
            "3 TrainLoss: 0.0037 TrainAcc: 0.5913, ValLoss: 0.0039, ValAcc: 0.5850\n",
            "Epoch 4/9\n",
            "----------\n",
            "idx: 0, loss: 0.989546000957489\n",
            "idx: 10, loss: 1.001564860343933\n",
            "idx: 20, loss: 0.9725764989852905\n",
            "idx: 30, loss: 0.9457572102546692\n",
            "idx: 40, loss: 0.9411596059799194\n",
            "idx: 50, loss: 1.0466639995574951\n",
            "idx: 60, loss: 0.9793736934661865\n",
            "idx: 70, loss: 0.9778034090995789\n",
            "idx: 80, loss: 1.0228713750839233\n",
            "idx: 90, loss: 0.9187171459197998\n",
            "idx: 100, loss: 0.9150187373161316\n",
            "idx: 110, loss: 0.9462406039237976\n",
            "idx: 120, loss: 1.023333191871643\n",
            "idx: 130, loss: 0.919701099395752\n",
            "idx: 140, loss: 0.9961987733840942\n",
            "idx: 150, loss: 0.8066791296005249\n",
            "idx: 160, loss: 0.8737565875053406\n",
            "idx: 170, loss: 0.8608065843582153\n",
            "idx: 180, loss: 1.0620867013931274\n",
            "idx: 190, loss: 0.9265614151954651\n",
            "idx: 200, loss: 0.9040757417678833\n",
            "idx: 210, loss: 0.888473391532898\n",
            "idx: 220, loss: 0.9437451958656311\n",
            "idx: 230, loss: 0.9806877374649048\n",
            "accuracy: 0.59\n",
            "4 TrainLoss: 0.0037 TrainAcc: 0.5915, ValLoss: 0.0039, ValAcc: 0.5851\n",
            "Epoch 5/9\n",
            "----------\n",
            "idx: 0, loss: 0.9867000579833984\n",
            "idx: 10, loss: 0.9991309642791748\n",
            "idx: 20, loss: 0.9697393774986267\n",
            "idx: 30, loss: 0.9444916248321533\n",
            "idx: 40, loss: 0.9375742673873901\n",
            "idx: 50, loss: 1.0454373359680176\n",
            "idx: 60, loss: 0.977224588394165\n",
            "idx: 70, loss: 0.9763249754905701\n",
            "idx: 80, loss: 1.020067811012268\n",
            "idx: 90, loss: 0.91795814037323\n",
            "idx: 100, loss: 0.910481333732605\n",
            "idx: 110, loss: 0.9436346292495728\n",
            "idx: 120, loss: 1.0217044353485107\n",
            "idx: 130, loss: 0.9169819951057434\n",
            "idx: 140, loss: 0.9971870183944702\n",
            "idx: 150, loss: 0.8070820569992065\n",
            "idx: 160, loss: 0.8737248182296753\n",
            "idx: 170, loss: 0.8604586124420166\n",
            "idx: 180, loss: 1.0594151020050049\n",
            "idx: 190, loss: 0.9250315427780151\n",
            "idx: 200, loss: 0.9030879735946655\n",
            "idx: 210, loss: 0.8866130113601685\n",
            "idx: 220, loss: 0.9427517056465149\n",
            "idx: 230, loss: 0.9806491136550903\n",
            "accuracy: 0.59\n",
            "5 TrainLoss: 0.0037 TrainAcc: 0.5917, ValLoss: 0.0039, ValAcc: 0.5852\n",
            "Epoch 6/9\n",
            "----------\n",
            "idx: 0, loss: 0.9832080006599426\n",
            "idx: 10, loss: 0.9980747699737549\n",
            "idx: 20, loss: 0.9688384532928467\n",
            "idx: 30, loss: 0.9437011480331421\n",
            "idx: 40, loss: 0.9406436681747437\n",
            "idx: 50, loss: 1.0441515445709229\n",
            "idx: 60, loss: 0.9777835607528687\n",
            "idx: 70, loss: 0.9748715162277222\n",
            "idx: 80, loss: 1.0185497999191284\n",
            "idx: 90, loss: 0.9169874787330627\n",
            "idx: 100, loss: 0.9064837694168091\n",
            "idx: 110, loss: 0.9420783519744873\n",
            "idx: 120, loss: 1.019484519958496\n",
            "idx: 130, loss: 0.9156664609909058\n",
            "idx: 140, loss: 0.996046781539917\n",
            "idx: 150, loss: 0.8070520758628845\n",
            "idx: 160, loss: 0.8737426400184631\n",
            "idx: 170, loss: 0.8597673773765564\n",
            "idx: 180, loss: 1.05735182762146\n",
            "idx: 190, loss: 0.9232555031776428\n",
            "idx: 200, loss: 0.899870753288269\n",
            "idx: 210, loss: 0.886317253112793\n",
            "idx: 220, loss: 0.9424010515213013\n",
            "idx: 230, loss: 0.9805880188941956\n",
            "accuracy: 0.59\n",
            "6 TrainLoss: 0.0037 TrainAcc: 0.5918, ValLoss: 0.0039, ValAcc: 0.5852\n",
            "Epoch 7/9\n",
            "----------\n",
            "idx: 0, loss: 0.9816612601280212\n",
            "idx: 10, loss: 0.9985805153846741\n",
            "idx: 20, loss: 0.9681087136268616\n",
            "idx: 30, loss: 0.9425945281982422\n",
            "idx: 40, loss: 0.9426054954528809\n",
            "idx: 50, loss: 1.0439213514328003\n",
            "idx: 60, loss: 0.975660502910614\n",
            "idx: 70, loss: 0.9736186861991882\n",
            "idx: 80, loss: 1.0156418085098267\n",
            "idx: 90, loss: 0.9166436791419983\n",
            "idx: 100, loss: 0.90422123670578\n",
            "idx: 110, loss: 0.9401495456695557\n",
            "idx: 120, loss: 1.0170643329620361\n",
            "idx: 130, loss: 0.9145447015762329\n",
            "idx: 140, loss: 0.9907722473144531\n",
            "idx: 150, loss: 0.8070546984672546\n",
            "idx: 160, loss: 0.873020350933075\n",
            "idx: 170, loss: 0.859539270401001\n",
            "idx: 180, loss: 1.0559474229812622\n",
            "idx: 190, loss: 0.9216125011444092\n",
            "idx: 200, loss: 0.8982266187667847\n",
            "idx: 210, loss: 0.8862149119377136\n",
            "idx: 220, loss: 0.9422072768211365\n",
            "idx: 230, loss: 0.9805796146392822\n",
            "accuracy: 0.59\n",
            "7 TrainLoss: 0.0037 TrainAcc: 0.5919, ValLoss: 0.0039, ValAcc: 0.5851\n",
            "Epoch 8/9\n",
            "----------\n",
            "idx: 0, loss: 0.9812125563621521\n",
            "idx: 10, loss: 0.9991596937179565\n",
            "idx: 20, loss: 0.9649899005889893\n",
            "idx: 30, loss: 0.9422155022621155\n",
            "idx: 40, loss: 0.9374834299087524\n",
            "idx: 50, loss: 1.043836236000061\n",
            "idx: 60, loss: 0.9726942777633667\n",
            "idx: 70, loss: 0.969944179058075\n",
            "idx: 80, loss: 1.0109864473342896\n",
            "idx: 90, loss: 0.9155851006507874\n",
            "idx: 100, loss: 0.9017885327339172\n",
            "idx: 110, loss: 0.9364089965820312\n",
            "idx: 120, loss: 1.0154178142547607\n",
            "idx: 130, loss: 0.9137063026428223\n",
            "idx: 140, loss: 0.9914692044258118\n",
            "idx: 150, loss: 0.8074777722358704\n",
            "idx: 160, loss: 0.8732997179031372\n",
            "idx: 170, loss: 0.8589761257171631\n",
            "idx: 180, loss: 1.0548444986343384\n",
            "idx: 190, loss: 0.9210582375526428\n",
            "idx: 200, loss: 0.897345244884491\n",
            "idx: 210, loss: 0.8851577639579773\n",
            "idx: 220, loss: 0.9412213563919067\n",
            "idx: 230, loss: 0.9805677533149719\n",
            "accuracy: 0.59\n",
            "8 TrainLoss: 0.0037 TrainAcc: 0.5921, ValLoss: 0.0039, ValAcc: 0.5851\n",
            "Epoch 9/9\n",
            "----------\n",
            "idx: 0, loss: 0.9781644344329834\n",
            "idx: 10, loss: 0.997445285320282\n",
            "idx: 20, loss: 0.9636409878730774\n",
            "idx: 30, loss: 0.9420079588890076\n",
            "idx: 40, loss: 0.9325903654098511\n",
            "idx: 50, loss: 1.0422663688659668\n",
            "idx: 60, loss: 0.9718549847602844\n",
            "idx: 70, loss: 0.9677394032478333\n",
            "idx: 80, loss: 1.0112662315368652\n",
            "idx: 90, loss: 0.9157037138938904\n",
            "idx: 100, loss: 0.8999205827713013\n",
            "idx: 110, loss: 0.93546062707901\n",
            "idx: 120, loss: 1.0147637128829956\n",
            "idx: 130, loss: 0.9129186868667603\n",
            "idx: 140, loss: 0.9886460304260254\n",
            "idx: 150, loss: 0.8065323829650879\n",
            "idx: 160, loss: 0.8726663589477539\n",
            "idx: 170, loss: 0.8596047759056091\n",
            "idx: 180, loss: 1.0529612302780151\n",
            "idx: 190, loss: 0.9202280044555664\n",
            "idx: 200, loss: 0.8943289518356323\n",
            "idx: 210, loss: 0.8849805593490601\n",
            "idx: 220, loss: 0.9405182003974915\n",
            "idx: 230, loss: 0.9805383682250977\n",
            "accuracy: 0.59\n",
            "9 TrainLoss: 0.0037 TrainAcc: 0.5924, ValLoss: 0.0039, ValAcc: 0.5852\n",
            "Training complete in 3m 1s\n",
            "Best val Acc: 0.097533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK_1RXjBzd6K",
        "outputId": "1aa30eec-2fbe-44cb-a0d4-b183e5d69e26"
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (relu4): ReLU()\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (relu5): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx_AWh7Dzd-P"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install onnx==1.8.1\n",
        "!pip install onnx_tf\n",
        "!pip install onnx_pytorch\n",
        "!pip install pytorch2keras\n",
        "#%tensorflow_version 1.x\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Q3mZnp6tfL"
      },
      "source": [
        "#Import needed packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from onnx_tf.backend import prepare\n",
        "from __future__ import print_function, division\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.autograd import Variable\n",
        "from pytorch2keras.converter import pytorch_to_keras\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzBfh_Rj6tkX"
      },
      "source": [
        "#model_ft = torch.load('/content/mnist_0.69.pkl')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKSVxpnr6tnS"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfV8TerTgMY"
      },
      "source": [
        "for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "  print(train_x.size(),train_label.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN_nW0oO6tru",
        "outputId": "7b6e1a02-9dde-4008-9d8d-be08cc7b96e8"
      },
      "source": [
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "feature_extract = True\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t conv1.weight\n",
            "\t conv1.bias\n",
            "\t conv2.weight\n",
            "\t conv2.bias\n",
            "\t fc1.weight\n",
            "\t fc1.bias\n",
            "\t fc2.weight\n",
            "\t fc2.bias\n",
            "\t fc3.weight\n",
            "\t fc3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYJG3l3b6tus",
        "outputId": "5cc1d604-46b0-4656-b1c4-5ac641145205"
      },
      "source": [
        "input_np = np.random.uniform(0, 1, (1, 1, 28, 28))\n",
        "input_var = Variable(torch.FloatTensor(input_np))\n",
        "k_model_ft = pytorch_to_keras(model_ft, input_var, [(1, 28, 28,)], verbose=True, change_ordering=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch2keras:Converter is called.\n",
            "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
            "DEBUG:pytorch2keras:Input_names:\n",
            "DEBUG:pytorch2keras:['input_0']\n",
            "DEBUG:pytorch2keras:Output_names:\n",
            "DEBUG:pytorch2keras:['output_0']\n",
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:[(1, 28, 28)]\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> input_0.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> output_0.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight conv1.weight with shape (6, 1, 5, 5).\n",
            "DEBUG:onnx2keras:Found weight conv1.bias with shape (6,).\n",
            "DEBUG:onnx2keras:Found weight conv2.weight with shape (16, 6, 5, 5).\n",
            "DEBUG:onnx2keras:Found weight conv2.bias with shape (16,).\n",
            "DEBUG:onnx2keras:Found weight fc1.weight with shape (120, 256).\n",
            "DEBUG:onnx2keras:Found weight fc1.bias with shape (120,).\n",
            "DEBUG:onnx2keras:Found weight fc2.weight with shape (84, 120).\n",
            "DEBUG:onnx2keras:Found weight fc2.bias with shape (84,).\n",
            "DEBUG:onnx2keras:Found weight fc3.weight with shape (10, 84).\n",
            "DEBUG:onnx2keras:Found weight fc3.bias with shape (10,).\n",
            "DEBUG:onnx2keras:Found input input_0 with shape (1, 28, 28)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 11\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [5, 5], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
            "DEBUG:onnx2keras:Check input 1 (name conv1.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name conv1.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "graph(%input_0 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n",
            "      %conv1.weight : Float(6, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=1, device=cpu),\n",
            "      %conv1.bias : Float(6, strides=[1], requires_grad=1, device=cpu),\n",
            "      %conv2.weight : Float(16, 6, 5, 5, strides=[150, 25, 5, 1], requires_grad=1, device=cpu),\n",
            "      %conv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
            "      %fc1.weight : Float(120, 256, strides=[256, 1], requires_grad=1, device=cpu),\n",
            "      %fc1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %fc2.weight : Float(84, 120, strides=[120, 1], requires_grad=1, device=cpu),\n",
            "      %fc2.bias : Float(84, strides=[1], requires_grad=1, device=cpu),\n",
            "      %fc3.weight : Float(10, 84, strides=[84, 1], requires_grad=1, device=cpu),\n",
            "      %fc3.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
            "  %11 : Float(1, 6, 24, 24, strides=[3456, 576, 24, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%input_0, %conv1.weight, %conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:440:0\n",
            "  %12 : Float(1, 6, 24, 24, strides=[3456, 576, 24, 1], requires_grad=1, device=cpu) = onnx::Relu(%11) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1298:0\n",
            "  %13 : Float(1, 6, 12, 12, strides=[864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%12) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718:0\n",
            "  %14 : Float(1, 16, 8, 8, strides=[1024, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%13, %conv2.weight, %conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:440:0\n",
            "  %15 : Float(1, 16, 8, 8, strides=[1024, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%14) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1298:0\n",
            "  %16 : Float(1, 16, 4, 4, strides=[256, 16, 4, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%15) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718:0\n",
            "  %17 : Long(4, strides=[1], device=cpu) = onnx::Shape(%16)\n",
            "  %18 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %19 : Long(device=cpu) = onnx::Gather[axis=0](%17, %18) # <ipython-input-2-14c1b543cfd2>:24:0\n",
            "  %20 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
            "  %21 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%19)\n",
            "  %22 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%20)\n",
            "  %23 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%21, %22)\n",
            "  %24 : Float(1, 256, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%16, %23) # <ipython-input-2-14c1b543cfd2>:24:0\n",
            "  %25 : Float(1, 120, strides=[120, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%24, %fc1.weight, %fc1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1847:0\n",
            "  %26 : Float(1, 120, strides=[120, 1], requires_grad=1, device=cpu) = onnx::Relu(%25) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1298:0\n",
            "  %27 : Float(1, 84, strides=[84, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%26, %fc2.weight, %fc2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1847:0\n",
            "  %28 : Float(1, 84, strides=[84, 1], requires_grad=1, device=cpu) = onnx::Relu(%27) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1298:0\n",
            "  %29 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%28, %fc3.weight, %fc3.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1847:0\n",
            "  %output_0 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Relu(%29) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1298:0\n",
            "  return (%output_0)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 24, 24), dtype=tf.float32, name=None), name='11/BiasAdd:0', description=\"created by layer '11'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 12\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 11).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 24, 24), dtype=tf.float32, name=None), name='12/Relu:0', description=\"created by layer '12'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 13\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 12).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 12, 12), dtype=tf.float32, name=None), name='13/MaxPool:0', description=\"created by layer '13'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 14\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [5, 5], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 13).\n",
            "DEBUG:onnx2keras:Check input 1 (name conv2.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name conv2.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 8, 8), dtype=tf.float32, name=None), name='14/BiasAdd:0', description=\"created by layer '14'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 15\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 14).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 8, 8), dtype=tf.float32, name=None), name='15/Relu:0', description=\"created by layer '15'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 16\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 15).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 4, 4), dtype=tf.float32, name=None), name='16/MaxPool:0', description=\"created by layer '16'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Shape\n",
            "DEBUG:onnx2keras:node_name: 17\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 16).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:shape:Actual shape:\n",
            "DEBUG:onnx2keras:shape:[None 16 4 4]\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None 16 4 4]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Constant\n",
            "DEBUG:onnx2keras:node_name: 18\n",
            "DEBUG:onnx2keras:node_params: {'value': array(0), 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> 0\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gather\n",
            "DEBUG:onnx2keras:node_name: 19\n",
            "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 17).\n",
            "DEBUG:onnx2keras:Check input 1 (name 18).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gather:Gather from numpy array\n",
            "DEBUG:onnx2keras:Output TF Layer -> None\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Constant\n",
            "DEBUG:onnx2keras:node_name: 20\n",
            "DEBUG:onnx2keras:node_params: {'value': array(-1), 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> -1\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Unsqueeze\n",
            "DEBUG:onnx2keras:node_name: 21\n",
            "DEBUG:onnx2keras:node_params: {'axes': [0], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 19).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:unsqueeze:Work with numpy types.\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Unsqueeze\n",
            "DEBUG:onnx2keras:node_name: 22\n",
            "DEBUG:onnx2keras:node_params: {'axes': [0], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 20).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:unsqueeze:Work with numpy types.\n",
            "DEBUG:onnx2keras:Output TF Layer -> [-1]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Concat\n",
            "DEBUG:onnx2keras:node_name: 23\n",
            "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 21).\n",
            "DEBUG:onnx2keras:Check input 1 (name 22).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:concat:Concat numpy arrays.\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None -1]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Reshape\n",
            "DEBUG:onnx2keras:node_name: 24\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 16).\n",
            "DEBUG:onnx2keras:Check input 1 (name 23).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
            "WARNING:onnx2keras:reshape:!!! IMPORTANT INFORMATION !!!\n",
            "WARNING:onnx2keras:reshape:The target shape if [None, -1] that means flatten.\n",
            "WARNING:onnx2keras:reshape:But the target ordering is NHWC, so we cant simply perform flatten\n",
            "WARNING:onnx2keras:reshape:The layer will be converted as lambda with tf.transpose\n",
            "WARNING:onnx2keras:reshape:---\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name=None), name='24/Reshape:0', description=\"created by layer '24'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 25\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 24).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc1.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc1.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 256, output units 120.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name=None), name='25/BiasAdd:0', description=\"created by layer '25'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 26\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 25).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name=None), name='26/Relu:0', description=\"created by layer '26'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 27\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 26).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc2.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc2.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 120, output units 84.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 84), dtype=tf.float32, name=None), name='27/BiasAdd:0', description=\"created by layer '27'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 28\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 27).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 84), dtype=tf.float32, name=None), name='28/Relu:0', description=\"created by layer '28'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 29\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 28).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc3.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc3.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 84, output units 10.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='29/BiasAdd:0', description=\"created by layer '29'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: output_0\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 29).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='output_0/Relu:0', description=\"created by layer 'output_0'\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48hAO3756tyz",
        "outputId": "258d2ed7-9d2e-4d54-c606-517ce036ca86"
      },
      "source": [
        "k_model_ft.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_0 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "11 (Conv2D)                  (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "12 (Activation)              (None, 24, 24, 6)         0         \n",
            "_________________________________________________________________\n",
            "13 (MaxPooling2D)            (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "14 (Conv2D)                  (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "15 (Activation)              (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "16 (MaxPooling2D)            (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "24_CHW (Lambda)              (None, 16, 4, 4)          0         \n",
            "_________________________________________________________________\n",
            "24 (Reshape)                 (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "25 (Dense)                   (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "26 (Activation)              (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "27 (Dense)                   (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "28 (Activation)              (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "29 (Dense)                   (None, 10)                850       \n",
            "_________________________________________________________________\n",
            "output_0 (Activation)        (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TvJ2CAe6uCn",
        "outputId": "fcaca42d-1da5-4b4e-fed4-e06c8713ae6c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 60000\n",
            "Number of original test examples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwBHnF8qVKtf",
        "outputId": "a774aee0-8efb-4160-ee70-470fff4f526e"
      },
      "source": [
        "print(tf.shape(x_train))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([60000    28    28     1], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FpLWl_OV08J"
      },
      "source": [
        "k_model_ft.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZLC2AxSVKx_",
        "outputId": "f18eded2-ce8d-4c71-ff08-d9764b9f3966"
      },
      "source": [
        "k_model_ft_history = k_model_ft.fit(x_train,y_train, epochs=epoch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 36s 3ms/step - loss: 0.9791 - accuracy: 0.5864\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9683 - accuracy: 0.5886\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9604 - accuracy: 0.5899\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9572 - accuracy: 0.5902\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9528 - accuracy: 0.5912\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9500 - accuracy: 0.5917\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9482 - accuracy: 0.5915\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9468 - accuracy: 0.5922\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9453 - accuracy: 0.5926\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9440 - accuracy: 0.5928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgjVDNfeVK3R"
      },
      "source": [
        "def export_history_csv2(history_):\n",
        "  since = time.time()\n",
        "  date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "  data_file = open('/content/tensorflow_exp_train_{}.csv'.format(date), mode='w+', newline='', encoding='utf-8')\n",
        "  data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', 'time','Elapse_time','date'])\n",
        "  for epoch_ in history_.epoch:\n",
        "    data_writer.writerow([history_.model,'tensorflow', 'hymenoptera', epoch_, '', \n",
        "                          history_.model.optimizer, '',history_.history['loss'][epoch_], history_.history['accuracy'][epoch_], \n",
        "                           '','',date])\n",
        "  data_file.close()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNHfNiYlbQQD"
      },
      "source": [
        "export_history_csv2(k_model_ft_history)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLierWDVbQU9"
      },
      "source": [
        "# Input to the model\n",
        "model_name = 'lenet5'\n",
        "torch.random.manual_seed(42)\n",
        "x = torch.randn(batch_size, 1, 28, 28, requires_grad=True)\n",
        "torch_out = model_ft(x)\n",
        "# Export the model\n",
        "torch.onnx.export(model_ft,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"model_ft-{}.onnx\".format(model_name),   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HVzF7pebQdR"
      },
      "source": [
        "import onnx\n",
        "onnx_model = onnx.load(\"model_ft-{}.onnx\".format(model_name))\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKsosy6ibQgE",
        "outputId": "a6f2b07c-c522-4712-d0e4-c54f99b89621"
      },
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"model_ft-{}.onnx\".format(model_name))\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "sxi9iCh1bQpE",
        "outputId": "128afe5b-330d-4bff-da3c-b047e065d8f7"
      },
      "source": [
        "np.testing.assert_array_equal(to_numpy(torch_out), ort_outs[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b723f764bbe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_equal\u001b[0;34m(x, y, err_msg, verbose)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Hide traceback for py.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n\u001b[0;32m--> 931\u001b[0;31m                          verbose=verbose, header='Arrays are not equal')\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not equal\n\nMismatched elements: 151 / 2560 (5.9%)\nMax absolute difference: 6.198883e-06\nMax relative difference: 6.071907e-05\n x: array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],...\n y: array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQulP8VScJhW",
        "outputId": "318125d9-fa74-4d79-fa84-2c401dcca23c"
      },
      "source": [
        "from onnx2keras import onnx_to_keras\n",
        "k_model_keras = onnx_to_keras(onnx_model, ['input'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:None\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> input.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> output.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight conv1.weight with shape (6, 1, 5, 5).\n",
            "DEBUG:onnx2keras:Found weight conv1.bias with shape (6,).\n",
            "DEBUG:onnx2keras:Found weight conv2.weight with shape (16, 6, 5, 5).\n",
            "DEBUG:onnx2keras:Found weight conv2.bias with shape (16,).\n",
            "DEBUG:onnx2keras:Found weight fc1.weight with shape (120, 256).\n",
            "DEBUG:onnx2keras:Found weight fc1.bias with shape (120,).\n",
            "DEBUG:onnx2keras:Found weight fc2.weight with shape (84, 120).\n",
            "DEBUG:onnx2keras:Found weight fc2.bias with shape (84,).\n",
            "DEBUG:onnx2keras:Found weight fc3.weight with shape (10, 84).\n",
            "DEBUG:onnx2keras:Found weight fc3.bias with shape (10,).\n",
            "DEBUG:onnx2keras:Found weight 31 with shape (1,).\n",
            "DEBUG:onnx2keras:Found input input with shape [1, 28, 28]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 11\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [5, 5], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name input).\n",
            "DEBUG:onnx2keras:Check input 1 (name conv1.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name conv1.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 24, 24), dtype=tf.float32, name=None), name='11/BiasAdd:0', description=\"created by layer '11'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 12\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 11).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 24, 24), dtype=tf.float32, name=None), name='12/Relu:0', description=\"created by layer '12'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 13\n",
            "DEBUG:onnx2keras:node_params: {'ceil_mode': 0, 'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 12).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 6, 12, 12), dtype=tf.float32, name=None), name='13/MaxPool:0', description=\"created by layer '13'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 14\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [5, 5], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 13).\n",
            "DEBUG:onnx2keras:Check input 1 (name conv2.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name conv2.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 8, 8), dtype=tf.float32, name=None), name='14/BiasAdd:0', description=\"created by layer '14'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 15\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 14).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 8, 8), dtype=tf.float32, name=None), name='15/Relu:0', description=\"created by layer '15'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 16\n",
            "DEBUG:onnx2keras:node_params: {'ceil_mode': 0, 'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 15).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 16, 4, 4), dtype=tf.float32, name=None), name='16/MaxPool:0', description=\"created by layer '16'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Shape\n",
            "DEBUG:onnx2keras:node_name: 17\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 16).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:shape:Actual shape:\n",
            "DEBUG:onnx2keras:shape:[None 16 4 4]\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None 16 4 4]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Constant\n",
            "DEBUG:onnx2keras:node_name: 18\n",
            "DEBUG:onnx2keras:node_params: {'value': array(0), 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> 0\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gather\n",
            "DEBUG:onnx2keras:node_name: 19\n",
            "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 17).\n",
            "DEBUG:onnx2keras:Check input 1 (name 18).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gather:Gather from numpy array\n",
            "DEBUG:onnx2keras:Output TF Layer -> None\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Unsqueeze\n",
            "DEBUG:onnx2keras:node_name: 21\n",
            "DEBUG:onnx2keras:node_params: {'axes': [0], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 19).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:unsqueeze:Work with numpy types.\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Concat\n",
            "DEBUG:onnx2keras:node_name: 23\n",
            "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 21).\n",
            "DEBUG:onnx2keras:Check input 1 (name 31).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:concat:Concat numpy arrays.\n",
            "DEBUG:onnx2keras:Output TF Layer -> [None -1]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Reshape\n",
            "DEBUG:onnx2keras:node_name: 24\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 16).\n",
            "DEBUG:onnx2keras:Check input 1 (name 23).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
            "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
            "DEBUG:onnx2keras:reshape:Target shape :\n",
            "DEBUG:onnx2keras:reshape:[-1]\n",
            "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Flatten.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name=None), name='24/Reshape:0', description=\"created by layer '24'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 25\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 24).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc1.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc1.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 256, output units 120.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name=None), name='25/BiasAdd:0', description=\"created by layer '25'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 26\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 25).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 120), dtype=tf.float32, name=None), name='26/Relu:0', description=\"created by layer '26'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 27\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 26).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc2.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc2.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 120, output units 84.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 84), dtype=tf.float32, name=None), name='27/BiasAdd:0', description=\"created by layer '27'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 28\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 27).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 84), dtype=tf.float32, name=None), name='28/Relu:0', description=\"created by layer '28'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 29\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 28).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc3.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc3.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 84, output units 10.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='29/BiasAdd:0', description=\"created by layer '29'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: output\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 29).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='output/Relu:0', description=\"created by layer 'output'\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV0VZIhydAWQ"
      },
      "source": [
        "x_train2 = tf.reshape(x_train, [-1,1, 28,28])\n",
        "x_test2 = tf.reshape(x_test, [-1,1, 28,28])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0PaMwT_cJuc"
      },
      "source": [
        "pred_k_keras = k_model_keras.predict(x_test2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfQXcqDTcKE1"
      },
      "source": [
        "# serialize model to JSON\n",
        "def save_keras(model, model_type='direct'):\n",
        "  model_json = model.to_json()\n",
        "  with open(\"k_model_{}_{}.json\".format(model_name, model_type), \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "  # serialize weights to HDF5\n",
        "  model.save_weights(\"k_model_{}_{}.h5\".format(model_name, model_type))\n",
        "  print(\"Saved model to disk\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDog5_wcKn6",
        "outputId": "11a97225-8b50-484b-a7a5-05f4e6c5953a"
      },
      "source": [
        "save_keras(k_model_ft, 'direct')\n",
        "save_keras(k_model_keras, 'through_onnx')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:h5py._conv:Creating converter from 5 to 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26na5CvncK6V"
      },
      "source": [
        "!pip install -U tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZEeEgZ-yMpG",
        "outputId": "7a2c6987-8545-43ab-ad6d-251a2b187c9b"
      },
      "source": [
        "import tf2onnx\n",
        "\n",
        "model_proto, external_tensor_storage = tf2onnx.convert.from_keras(k_model_keras,\n",
        "                input_signature=None, opset=None, custom_ops=None,\n",
        "                custom_op_handlers=None, custom_rewriter=None,\n",
        "                inputs_as_nchw=None, extra_opset=None, shape_override=None,\n",
        "                 target=None, large_model=False, output_path='model_ft_keras-{}2.onnx'.format(model_name))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:662: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:662: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tf2onnx.tfonnx:Using tensorflow=2.5.0, onnx=1.8.1, tf2onnx=1.9.1/8e8c23\n",
            "INFO:tf2onnx.tfonnx:Using opset <onnx, 9>\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "DEBUG:tf2onnx.graph:Making node: Name=Identity, OP=Identity\n",
            "DEBUG:tf2onnx.graph:Made node: Identity\n",
            "OP=Identity\n",
            "Name=Identity\n",
            "Inputs:\n",
            "\tmodel_1/output/Relu:0=Relu, [-1, 10], 1\n",
            "Outpus:\n",
            "\tIdentity_raw_output___4:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=Identity_graph_outputs_Identity__5, OP=Identity\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [Identity_graph_outputs_Identity__5]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [output] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [output] to [-1, 10]\n",
            "DEBUG:tf2onnx.graph:Made node: Identity_graph_outputs_Identity__5\n",
            "OP=Identity\n",
            "Name=Identity_graph_outputs_Identity__5\n",
            "Inputs:\n",
            "\tIdentity_raw_output___4:0=Identity, [-1, 10], 1\n",
            "Outpus:\n",
            "\toutput=[-1, 10], 1\n",
            "DEBUG:tf2onnx.rewriter.lstm_rewriter:enter lstm rewriter\n",
            "DEBUG:tf2onnx.rewriter.gru_rewriter:enter gru rewriter\n",
            "DEBUG:tf2onnx.rewriter.custom_rnn_rewriter:enter custom rnn rewriter\n",
            "DEBUG:tf2onnx.rewriter.loop_rewriter:enter loop rewriter\n",
            "DEBUG:tf2onnx.rewriter.cond_rewriter:enter cond pre rewrite\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model_1/11/BiasAdd, OP=Conv2D\n",
            "DEBUG:tf2onnx.graph:Made node: model_1/11/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model_1/11/BiasAdd\n",
            "Inputs:\n",
            "\tinput=Placeholder, [-1, 1, 28, 28], 1\n",
            "\tmodel_1/11/Conv2D/ReadVariableOp:0=Const, [5, 5, 1, 6], 1\n",
            "\tmodel_1/11/BiasAdd/ReadVariableOp:0=Const, [6], 1\n",
            "Outpus:\n",
            "\tmodel_1/11/BiasAdd:0=[-1, 6, 24, 24], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model_1/14/BiasAdd, OP=Conv2D\n",
            "DEBUG:tf2onnx.graph:Made node: model_1/14/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model_1/14/BiasAdd\n",
            "Inputs:\n",
            "\tmodel_1/13/MaxPool:0=MaxPool, [-1, 6, 12, 12], 1\n",
            "\tmodel_1/14/Conv2D/ReadVariableOp:0=Const, [5, 5, 6, 16], 1\n",
            "\tmodel_1/14/BiasAdd/ReadVariableOp:0=Const, [16], 1\n",
            "Outpus:\n",
            "\tmodel_1/14/BiasAdd:0=[-1, 16, 8, 8], 1\n",
            "VERBOSE:tf2onnx.tfonnx:Mapping TF node to ONNX node(s)\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/29/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/29/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/29/MatMul/ReadVariableOp:0=[84, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/29/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/29/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/29/BiasAdd/ReadVariableOp:0=[10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/27/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/27/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/27/MatMul/ReadVariableOp:0=[120, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/27/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/27/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/27/BiasAdd/ReadVariableOp:0=[84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/25/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/25/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/25/MatMul/ReadVariableOp:0=[256, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/25/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/25/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/25/BiasAdd/ReadVariableOp:0=[120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/24/transpose/perm\n",
            "OP=Const\n",
            "Name=model_1/24/transpose/perm\n",
            "Outpus:\n",
            "\tmodel_1/24/transpose/perm:0=[4], 6\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/24/Const\n",
            "OP=Const\n",
            "Name=model_1/24/Const\n",
            "Outpus:\n",
            "\tmodel_1/24/Const:0=[2], 6\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/14/Conv2D/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/14/Conv2D/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/14/Conv2D/ReadVariableOp:0=[5, 5, 6, 16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/14/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/14/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/14/BiasAdd/ReadVariableOp:0=[16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/11/Conv2D/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/11/Conv2D/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/11/Conv2D/ReadVariableOp:0=[5, 5, 1, 6], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/11/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model_1/11/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel_1/11/BiasAdd/ReadVariableOp:0=[6], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: input\n",
            "OP=Placeholder\n",
            "Name=input\n",
            "Outpus:\n",
            "\tinput=[-1, 1, 28, 28], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/11/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model_1/11/BiasAdd\n",
            "Inputs:\n",
            "\tinput=Placeholder, [-1, 1, 28, 28], 1\n",
            "\tmodel_1/11/Conv2D/ReadVariableOp:0=Const, [5, 5, 1, 6], 1\n",
            "\tmodel_1/11/BiasAdd/ReadVariableOp:0=Const, [6], 1\n",
            "Outpus:\n",
            "\tmodel_1/11/BiasAdd:0=[-1, 6, 24, 24], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/12/Relu\n",
            "OP=Relu\n",
            "Name=model_1/12/Relu\n",
            "Inputs:\n",
            "\tmodel_1/11/BiasAdd:0=Conv, [-1, 6, 24, 24], 1\n",
            "Outpus:\n",
            "\tmodel_1/12/Relu:0=[-1, 6, 24, 24], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/13/MaxPool\n",
            "OP=MaxPool\n",
            "Name=model_1/13/MaxPool\n",
            "Inputs:\n",
            "\tmodel_1/12/Relu:0=Relu, [-1, 6, 24, 24], 1\n",
            "Outpus:\n",
            "\tmodel_1/13/MaxPool:0=[-1, 6, 12, 12], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/14/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model_1/14/BiasAdd\n",
            "Inputs:\n",
            "\tmodel_1/13/MaxPool:0=MaxPool, [-1, 6, 12, 12], 1\n",
            "\tmodel_1/14/Conv2D/ReadVariableOp:0=Const, [5, 5, 6, 16], 1\n",
            "\tmodel_1/14/BiasAdd/ReadVariableOp:0=Const, [16], 1\n",
            "Outpus:\n",
            "\tmodel_1/14/BiasAdd:0=[-1, 16, 8, 8], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/15/Relu\n",
            "OP=Relu\n",
            "Name=model_1/15/Relu\n",
            "Inputs:\n",
            "\tmodel_1/14/BiasAdd:0=Conv, [-1, 16, 8, 8], 1\n",
            "Outpus:\n",
            "\tmodel_1/15/Relu:0=[-1, 16, 8, 8], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/16/MaxPool\n",
            "OP=MaxPool\n",
            "Name=model_1/16/MaxPool\n",
            "Inputs:\n",
            "\tmodel_1/15/Relu:0=Relu, [-1, 16, 8, 8], 1\n",
            "Outpus:\n",
            "\tmodel_1/16/MaxPool:0=[-1, 16, 4, 4], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/24/transpose\n",
            "OP=Transpose\n",
            "Name=model_1/24/transpose\n",
            "Inputs:\n",
            "\tmodel_1/16/MaxPool:0=MaxPool, [-1, 16, 4, 4], 1\n",
            "\tmodel_1/24/transpose/perm:0=Const, [4], 6\n",
            "Outpus:\n",
            "\tmodel_1/24/transpose:0=[-1, 4, 4, 16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/24/Reshape\n",
            "OP=Reshape\n",
            "Name=model_1/24/Reshape\n",
            "Inputs:\n",
            "\tmodel_1/24/transpose:0=Transpose, [-1, 4, 4, 16], 1\n",
            "\tmodel_1/24/Const:0=Const, [2], 6\n",
            "Outpus:\n",
            "\tmodel_1/24/Reshape:0=[-1, 256], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model_1/24/Reshape__7, OP=Cast\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model_1/24/Reshape__7]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model_1/24/Reshape__7:0] to 7\n",
            "DEBUG:tf2onnx.graph:Set shape of [model_1/24/Reshape__7:0] to [2]\n",
            "DEBUG:tf2onnx.graph:Made node: model_1/24/Reshape__7\n",
            "OP=Cast\n",
            "Name=model_1/24/Reshape__7\n",
            "Inputs:\n",
            "\tmodel_1/24/Const:0=Const, [2], 6\n",
            "Outpus:\n",
            "\tmodel_1/24/Reshape__7:0=[2], 7\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/25/MatMul\n",
            "OP=MatMul\n",
            "Name=model_1/25/MatMul\n",
            "Inputs:\n",
            "\tmodel_1/24/Reshape:0=Reshape, [-1, 256], 1\n",
            "\tmodel_1/25/MatMul/ReadVariableOp:0=Const, [256, 120], 1\n",
            "Outpus:\n",
            "\tmodel_1/25/MatMul:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/25/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model_1/25/BiasAdd\n",
            "Inputs:\n",
            "\tmodel_1/25/MatMul:0=MatMul, [-1, 120], 1\n",
            "\tmodel_1/25/BiasAdd/ReadVariableOp:0=Const, [120], 1\n",
            "Outpus:\n",
            "\tmodel_1/25/BiasAdd:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/26/Relu\n",
            "OP=Relu\n",
            "Name=model_1/26/Relu\n",
            "Inputs:\n",
            "\tmodel_1/25/BiasAdd:0=Add, [-1, 120], 1\n",
            "Outpus:\n",
            "\tmodel_1/26/Relu:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/27/MatMul\n",
            "OP=MatMul\n",
            "Name=model_1/27/MatMul\n",
            "Inputs:\n",
            "\tmodel_1/26/Relu:0=Relu, [-1, 120], 1\n",
            "\tmodel_1/27/MatMul/ReadVariableOp:0=Const, [120, 84], 1\n",
            "Outpus:\n",
            "\tmodel_1/27/MatMul:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/27/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model_1/27/BiasAdd\n",
            "Inputs:\n",
            "\tmodel_1/27/MatMul:0=MatMul, [-1, 84], 1\n",
            "\tmodel_1/27/BiasAdd/ReadVariableOp:0=Const, [84], 1\n",
            "Outpus:\n",
            "\tmodel_1/27/BiasAdd:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/28/Relu\n",
            "OP=Relu\n",
            "Name=model_1/28/Relu\n",
            "Inputs:\n",
            "\tmodel_1/27/BiasAdd:0=Add, [-1, 84], 1\n",
            "Outpus:\n",
            "\tmodel_1/28/Relu:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/29/MatMul\n",
            "OP=MatMul\n",
            "Name=model_1/29/MatMul\n",
            "Inputs:\n",
            "\tmodel_1/28/Relu:0=Relu, [-1, 84], 1\n",
            "\tmodel_1/29/MatMul/ReadVariableOp:0=Const, [84, 10], 1\n",
            "Outpus:\n",
            "\tmodel_1/29/MatMul:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/29/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model_1/29/BiasAdd\n",
            "Inputs:\n",
            "\tmodel_1/29/MatMul:0=MatMul, [-1, 10], 1\n",
            "\tmodel_1/29/BiasAdd/ReadVariableOp:0=Const, [10], 1\n",
            "Outpus:\n",
            "\tmodel_1/29/BiasAdd:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model_1/output/Relu\n",
            "OP=Relu\n",
            "Name=model_1/output/Relu\n",
            "Inputs:\n",
            "\tmodel_1/29/BiasAdd:0=Add, [-1, 10], 1\n",
            "Outpus:\n",
            "\tmodel_1/output/Relu:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: Identity\n",
            "OP=Identity\n",
            "Name=Identity\n",
            "Inputs:\n",
            "\tmodel_1/output/Relu:0=Relu, [-1, 10], 1\n",
            "Outpus:\n",
            "\tIdentity_raw_output___4:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: Identity_graph_outputs_Identity__5\n",
            "OP=Identity\n",
            "Name=Identity_graph_outputs_Identity__5\n",
            "Inputs:\n",
            "\tIdentity_raw_output___4:0=Identity, [-1, 10], 1\n",
            "Outpus:\n",
            "\toutput=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:explicitly skip node Identity_graph_outputs_Identity__5\n",
            "VERBOSE:tf2onnx.tfonnx:Summay Stats:\n",
            "\ttensorflow ops: Counter({'Const': 12, 'BiasAdd': 5, 'Relu': 5, 'MatMul': 3, 'Conv2D': 2, 'MaxPool': 2, 'Placeholder': 1, 'Transpose': 1, 'Reshape': 1, 'Identity': 1})\n",
            "\ttensorflow attr: Counter({'T': 40, 'dtype': 26, 'value': 24, 'data_format': 18, 'strides': 8, 'explicit_paddings': 8, 'padding': 8, 'transpose_a': 6, 'transpose_b': 6, 'dilations': 4, 'use_cudnn_on_gpu': 4, 'ksize': 4, 'shape': 2, 'Tperm': 2, 'Tshape': 2})\n",
            "\tonnx mapped: Counter({'Const': 12, 'Relu': 5, 'MatMul': 3, 'BiasAdd': 3, 'Conv2D': 2, 'MaxPool': 2, 'Placeholder': 1, 'Transpose': 1, 'Reshape': 1, 'Identity': 1})\n",
            "\tonnx unmapped: Counter()\n",
            "INFO:tf2onnx.optimizer:Optimizing ONNX model\n",
            "VERBOSE:tf2onnx.optimizer:Apply optimize_transpose\n",
            "DEBUG:tf2onnx.optimizer.TransposeOptimizer:finish after 0 iteration(s)\n",
            "VERBOSE:tf2onnx.optimizer.TransposeOptimizer:Const -1 (12->11)\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_redundant_upsample\n",
            "VERBOSE:tf2onnx.optimizer.UpsampleOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply fold_constants\n",
            "DEBUG:tf2onnx.graph:Making node: Name=const_fold_opt__8, OP=Const\n",
            "DEBUG:tf2onnx.graph:Made node: const_fold_opt__8\n",
            "OP=Const\n",
            "Name=const_fold_opt__8\n",
            "Outpus:\n",
            "\tconst_fold_opt__8=None, 7\n",
            "VERBOSE:tf2onnx.optimizer.ConstFoldOptimizer:Cast -1 (1->0)\n",
            "VERBOSE:tf2onnx.optimizer:Apply const_dequantize_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ConstDequantizeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply loop_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.LoopOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply merge_duplication\n",
            "VERBOSE:tf2onnx.optimizer.MergeDuplicatedNodesOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply reshape_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ReshapeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply global_pool_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.GlobalPoolOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply q_dq_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.QDQOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_identity\n",
            "VERBOSE:tf2onnx.optimizer.IdentityOptimizer:Identity -2 (2->0)\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_back_to_back\n",
            "VERBOSE:tf2onnx.optimizer.BackToBackOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply einsum_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.EinsumOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply optimize_transpose\n",
            "DEBUG:tf2onnx.optimizer.TransposeOptimizer:finish after 0 iteration(s)\n",
            "VERBOSE:tf2onnx.optimizer.TransposeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_redundant_upsample\n",
            "VERBOSE:tf2onnx.optimizer.UpsampleOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply fold_constants\n",
            "VERBOSE:tf2onnx.optimizer.ConstFoldOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply const_dequantize_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ConstDequantizeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply loop_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.LoopOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply merge_duplication\n",
            "VERBOSE:tf2onnx.optimizer.MergeDuplicatedNodesOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply reshape_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ReshapeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply global_pool_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.GlobalPoolOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply q_dq_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.QDQOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_identity\n",
            "VERBOSE:tf2onnx.optimizer.IdentityOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_back_to_back\n",
            "VERBOSE:tf2onnx.optimizer.BackToBackOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply einsum_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.EinsumOptimizer:no change\n",
            "INFO:tf2onnx.optimizer:After optimization: Cast -1 (1->0), Const -1 (12->11), Identity -2 (2->0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ5dCGcNyMyU"
      },
      "source": [
        "onnx_model_keras = onnx.load('model_ft_keras-{}2.onnx'.format(model_name))\n",
        "onnx.checker.check_model(onnx_model_keras)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1HrpkOOyM43"
      },
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session2 = onnxruntime.InferenceSession('model_ft_keras-{}2.onnx'.format(model_name))\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs2 = {ort_session2.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs2 = ort_session2.run(None, ort_inputs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "wONSmh6UyNQM",
        "outputId": "bffd2f09-3f42-42a8-8a51-ebe85f6b5f3a"
      },
      "source": [
        "np.testing.assert_array_equal(ort_outs2[0], ort_outs[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-bae493421143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mort_outs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_equal\u001b[0;34m(x, y, err_msg, verbose)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Hide traceback for py.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n\u001b[0;32m--> 931\u001b[0;31m                          verbose=verbose, header='Arrays are not equal')\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not equal\n\nMismatched elements: 228 / 2560 (8.91%)\nMax absolute difference: 9.380518\nMax relative difference: 13.465907\n x: array([[0.      , 0.264218, 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [1.261286, 0.      , 0.      , ..., 0.      , 0.193427, 0.      ],...\n y: array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqANDnOfy5es",
        "outputId": "0d37ba8e-9ba4-4ffd-9480-5964a8f241dc"
      },
      "source": [
        "model_proto, external_tensor_storage = tf2onnx.convert.from_keras(k_model_ft,\n",
        "                input_signature=None, opset=None, custom_ops=None,\n",
        "                custom_op_handlers=None, custom_rewriter=None,\n",
        "                inputs_as_nchw=None, extra_opset=None, shape_override=None,\n",
        "                 target=None, large_model=False, output_path='model_ft-{}2.onnx'.format(model_name))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tf2onnx.tfonnx:Using tensorflow=2.5.0, onnx=1.8.1, tf2onnx=1.9.1/8e8c23\n",
            "INFO:tf2onnx.tfonnx:Using opset <onnx, 9>\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "DEBUG:tf2onnx.graph:Making node: Name=Identity, OP=Identity\n",
            "DEBUG:tf2onnx.graph:Made node: Identity\n",
            "OP=Identity\n",
            "Name=Identity\n",
            "Inputs:\n",
            "\tmodel/output_0/Relu:0=Relu, [-1, 10], 1\n",
            "Outpus:\n",
            "\tIdentity_raw_output___12:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=Identity_graph_outputs_Identity__13, OP=Identity\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [Identity_graph_outputs_Identity__13]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [output_0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [output_0] to [-1, 10]\n",
            "DEBUG:tf2onnx.graph:Made node: Identity_graph_outputs_Identity__13\n",
            "OP=Identity\n",
            "Name=Identity_graph_outputs_Identity__13\n",
            "Inputs:\n",
            "\tIdentity_raw_output___12:0=Identity, [-1, 10], 1\n",
            "Outpus:\n",
            "\toutput_0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:op name model/24/Reshape/shape, 2, 0\n",
            "DEBUG:tf2onnx.graph:Making node: Name=Flatten__15, OP=Flatten\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [Flatten__15]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [Flatten__15:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [Flatten__15:0] to [-1, 256]\n",
            "DEBUG:tf2onnx.graph:Made node: Flatten__15\n",
            "OP=Flatten\n",
            "Name=Flatten__15\n",
            "Inputs:\n",
            "\tmodel/24_CHW/transpose:0=Transpose, [-1, 16, 4, 4], 1\n",
            "Outpus:\n",
            "\tFlatten__15:0=[-1, 256], 1\n",
            "DEBUG:tf2onnx.rewriter.lstm_rewriter:enter lstm rewriter\n",
            "DEBUG:tf2onnx.rewriter.gru_rewriter:enter gru rewriter\n",
            "DEBUG:tf2onnx.rewriter.custom_rnn_rewriter:enter custom rnn rewriter\n",
            "DEBUG:tf2onnx.rewriter.loop_rewriter:enter loop rewriter\n",
            "DEBUG:tf2onnx.rewriter.cond_rewriter:enter cond pre rewrite\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/11/BiasAdd, OP=Conv2D\n",
            "DEBUG:tf2onnx.graph:Made node: model/11/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model/11/BiasAdd\n",
            "Inputs:\n",
            "\tinput_0=Placeholder, [-1, 28, 28, 1], 1\n",
            "\tmodel/11/Conv2D/ReadVariableOp:0=Const, [5, 5, 1, 6], 1\n",
            "\tmodel/11/BiasAdd/ReadVariableOp:0=Const, [6], 1\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd:0=[-1, 24, 24, 6], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/14/BiasAdd, OP=Conv2D\n",
            "DEBUG:tf2onnx.graph:Made node: model/14/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model/14/BiasAdd\n",
            "Inputs:\n",
            "\tmodel/13/MaxPool:0=MaxPool, [-1, 12, 12, 6], 1\n",
            "\tmodel/14/Conv2D/ReadVariableOp:0=Const, [5, 5, 6, 16], 1\n",
            "\tmodel/14/BiasAdd/ReadVariableOp:0=Const, [16], 1\n",
            "Outpus:\n",
            "\tmodel/14/BiasAdd:0=[-1, 8, 8, 16], 1\n",
            "VERBOSE:tf2onnx.tfonnx:Mapping TF node to ONNX node(s)\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/29/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/29/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/29/MatMul/ReadVariableOp:0=[84, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/29/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/29/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/29/BiasAdd/ReadVariableOp:0=[10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/27/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/27/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/27/MatMul/ReadVariableOp:0=[120, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/27/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/27/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/27/BiasAdd/ReadVariableOp:0=[84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/25/MatMul/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/25/MatMul/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/25/MatMul/ReadVariableOp:0=[256, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/25/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/25/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/25/BiasAdd/ReadVariableOp:0=[120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/24_CHW/transpose/perm\n",
            "OP=Const\n",
            "Name=model/24_CHW/transpose/perm\n",
            "Outpus:\n",
            "\tmodel/24_CHW/transpose/perm:0=[4], 6\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/14/Conv2D/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/14/Conv2D/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/14/Conv2D/ReadVariableOp:0=[5, 5, 6, 16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/14/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/14/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/14/BiasAdd/ReadVariableOp:0=[16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/11/Conv2D/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/11/Conv2D/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/11/Conv2D/ReadVariableOp:0=[5, 5, 1, 6], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/11/BiasAdd/ReadVariableOp\n",
            "OP=Const\n",
            "Name=model/11/BiasAdd/ReadVariableOp\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd/ReadVariableOp:0=[6], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: input_0\n",
            "OP=Placeholder\n",
            "Name=input_0\n",
            "Outpus:\n",
            "\tinput_0=[-1, 28, 28, 1], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/11/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model/11/BiasAdd\n",
            "Inputs:\n",
            "\tinput_0=Placeholder, [-1, 28, 28, 1], 1\n",
            "\tmodel/11/Conv2D/ReadVariableOp:0=Const, [5, 5, 1, 6], 1\n",
            "\tmodel/11/BiasAdd/ReadVariableOp:0=Const, [6], 1\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd:0=[-1, 24, 24, 6], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/11/BiasAdd__17, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/11/BiasAdd__17]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/11/BiasAdd__17:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/11/BiasAdd__17:0] to [1, 28, 28, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/11/BiasAdd__17\n",
            "OP=Transpose\n",
            "Name=model/11/BiasAdd__17\n",
            "Inputs:\n",
            "\tinput_0=Placeholder, [-1, 28, 28, 1], 1\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd__17:0=[1, 28, 28, -1], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/11/BiasAdd__19, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/11/BiasAdd__19]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/11/BiasAdd__19:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/11/BiasAdd__19:0] to [6, 24, 24, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/11/BiasAdd__19\n",
            "OP=Transpose\n",
            "Name=model/11/BiasAdd__19\n",
            "Inputs:\n",
            "\tmodel/11/BiasAdd:0=Conv, [-1, 24, 24, 6], 1\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd__19:0=[6, 24, 24, -1], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/12/Relu\n",
            "OP=Relu\n",
            "Name=model/12/Relu\n",
            "Inputs:\n",
            "\tmodel/11/BiasAdd__19:0=Transpose, [-1, 24, 24, 6], 1\n",
            "Outpus:\n",
            "\tmodel/12/Relu:0=[-1, 24, 24, 6], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/13/MaxPool\n",
            "OP=MaxPool\n",
            "Name=model/13/MaxPool\n",
            "Inputs:\n",
            "\tmodel/12/Relu:0=Relu, [-1, 24, 24, 6], 1\n",
            "Outpus:\n",
            "\tmodel/13/MaxPool:0=[-1, 12, 12, 6], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/13/MaxPool__21, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/13/MaxPool__21]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/13/MaxPool__21:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/13/MaxPool__21:0] to [6, 24, 24, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/13/MaxPool__21\n",
            "OP=Transpose\n",
            "Name=model/13/MaxPool__21\n",
            "Inputs:\n",
            "\tmodel/12/Relu:0=Relu, [-1, 24, 24, 6], 1\n",
            "Outpus:\n",
            "\tmodel/13/MaxPool__21:0=[6, 24, 24, -1], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/13/MaxPool__23, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/13/MaxPool__23]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/13/MaxPool__23:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/13/MaxPool__23:0] to [6, 12, 12, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/13/MaxPool__23\n",
            "OP=Transpose\n",
            "Name=model/13/MaxPool__23\n",
            "Inputs:\n",
            "\tmodel/13/MaxPool:0=MaxPool, [-1, 12, 12, 6], 1\n",
            "Outpus:\n",
            "\tmodel/13/MaxPool__23:0=[6, 12, 12, -1], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/14/BiasAdd\n",
            "OP=Conv2D\n",
            "Name=model/14/BiasAdd\n",
            "Inputs:\n",
            "\tmodel/13/MaxPool__23:0=Transpose, [-1, 12, 12, 6], 1\n",
            "\tmodel/14/Conv2D/ReadVariableOp:0=Const, [5, 5, 6, 16], 1\n",
            "\tmodel/14/BiasAdd/ReadVariableOp:0=Const, [16], 1\n",
            "Outpus:\n",
            "\tmodel/14/BiasAdd:0=[-1, 8, 8, 16], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/14/BiasAdd__25, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/14/BiasAdd__25]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/14/BiasAdd__25:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/14/BiasAdd__25:0] to [6, 12, 12, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/14/BiasAdd__25\n",
            "OP=Transpose\n",
            "Name=model/14/BiasAdd__25\n",
            "Inputs:\n",
            "\tmodel/13/MaxPool__23:0=Transpose, [-1, 12, 12, 6], 1\n",
            "Outpus:\n",
            "\tmodel/14/BiasAdd__25:0=[6, 12, 12, -1], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/14/BiasAdd__27, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/14/BiasAdd__27]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/14/BiasAdd__27:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/14/BiasAdd__27:0] to [16, 8, 8, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/14/BiasAdd__27\n",
            "OP=Transpose\n",
            "Name=model/14/BiasAdd__27\n",
            "Inputs:\n",
            "\tmodel/14/BiasAdd:0=Conv, [-1, 8, 8, 16], 1\n",
            "Outpus:\n",
            "\tmodel/14/BiasAdd__27:0=[16, 8, 8, -1], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/15/Relu\n",
            "OP=Relu\n",
            "Name=model/15/Relu\n",
            "Inputs:\n",
            "\tmodel/14/BiasAdd__27:0=Transpose, [-1, 8, 8, 16], 1\n",
            "Outpus:\n",
            "\tmodel/15/Relu:0=[-1, 8, 8, 16], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/16/MaxPool\n",
            "OP=MaxPool\n",
            "Name=model/16/MaxPool\n",
            "Inputs:\n",
            "\tmodel/15/Relu:0=Relu, [-1, 8, 8, 16], 1\n",
            "Outpus:\n",
            "\tmodel/16/MaxPool:0=[-1, 4, 4, 16], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/16/MaxPool__29, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/16/MaxPool__29]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/16/MaxPool__29:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/16/MaxPool__29:0] to [16, 8, 8, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/16/MaxPool__29\n",
            "OP=Transpose\n",
            "Name=model/16/MaxPool__29\n",
            "Inputs:\n",
            "\tmodel/15/Relu:0=Relu, [-1, 8, 8, 16], 1\n",
            "Outpus:\n",
            "\tmodel/16/MaxPool__29:0=[16, 8, 8, -1], 1\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/16/MaxPool__31, OP=Transpose\n",
            "DEBUG:tf2onnx.graph:Infer shape and dtype for [model/16/MaxPool__31]\n",
            "DEBUG:tf2onnx.graph:Set dtype of [model/16/MaxPool__31:0] to 1\n",
            "DEBUG:tf2onnx.graph:Set shape of [model/16/MaxPool__31:0] to [16, 4, 4, -1]\n",
            "DEBUG:tf2onnx.graph:Made node: model/16/MaxPool__31\n",
            "OP=Transpose\n",
            "Name=model/16/MaxPool__31\n",
            "Inputs:\n",
            "\tmodel/16/MaxPool:0=MaxPool, [-1, 4, 4, 16], 1\n",
            "Outpus:\n",
            "\tmodel/16/MaxPool__31:0=[16, 4, 4, -1], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/24_CHW/transpose\n",
            "OP=Transpose\n",
            "Name=model/24_CHW/transpose\n",
            "Inputs:\n",
            "\tmodel/16/MaxPool__31:0=Transpose, [-1, 4, 4, 16], 1\n",
            "\tmodel/24_CHW/transpose/perm:0=Const, [4], 6\n",
            "Outpus:\n",
            "\tmodel/24_CHW/transpose:0=[-1, 16, 4, 4], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: Flatten__15\n",
            "OP=Flatten\n",
            "Name=Flatten__15\n",
            "Inputs:\n",
            "\tmodel/24_CHW/transpose:0=Transpose, [-1, 16, 4, 4], 1\n",
            "Outpus:\n",
            "\tFlatten__15:0=[-1, 16, 16], 1\n",
            "DEBUG:tf2onnx.tfonnx:explicitly skip node Flatten__15\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/25/MatMul\n",
            "OP=MatMul\n",
            "Name=model/25/MatMul\n",
            "Inputs:\n",
            "\tFlatten__15:0=Flatten, [-1, 16, 16], 1\n",
            "\tmodel/25/MatMul/ReadVariableOp:0=Const, [256, 120], 1\n",
            "Outpus:\n",
            "\tmodel/25/MatMul:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/25/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model/25/BiasAdd\n",
            "Inputs:\n",
            "\tmodel/25/MatMul:0=MatMul, [-1, 120], 1\n",
            "\tmodel/25/BiasAdd/ReadVariableOp:0=Const, [120], 1\n",
            "Outpus:\n",
            "\tmodel/25/BiasAdd:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/26/Relu\n",
            "OP=Relu\n",
            "Name=model/26/Relu\n",
            "Inputs:\n",
            "\tmodel/25/BiasAdd:0=Add, [-1, 120], 1\n",
            "Outpus:\n",
            "\tmodel/26/Relu:0=[-1, 120], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/27/MatMul\n",
            "OP=MatMul\n",
            "Name=model/27/MatMul\n",
            "Inputs:\n",
            "\tmodel/26/Relu:0=Relu, [-1, 120], 1\n",
            "\tmodel/27/MatMul/ReadVariableOp:0=Const, [120, 84], 1\n",
            "Outpus:\n",
            "\tmodel/27/MatMul:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/27/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model/27/BiasAdd\n",
            "Inputs:\n",
            "\tmodel/27/MatMul:0=MatMul, [-1, 84], 1\n",
            "\tmodel/27/BiasAdd/ReadVariableOp:0=Const, [84], 1\n",
            "Outpus:\n",
            "\tmodel/27/BiasAdd:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/28/Relu\n",
            "OP=Relu\n",
            "Name=model/28/Relu\n",
            "Inputs:\n",
            "\tmodel/27/BiasAdd:0=Add, [-1, 84], 1\n",
            "Outpus:\n",
            "\tmodel/28/Relu:0=[-1, 84], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/29/MatMul\n",
            "OP=MatMul\n",
            "Name=model/29/MatMul\n",
            "Inputs:\n",
            "\tmodel/28/Relu:0=Relu, [-1, 84], 1\n",
            "\tmodel/29/MatMul/ReadVariableOp:0=Const, [84, 10], 1\n",
            "Outpus:\n",
            "\tmodel/29/MatMul:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/29/BiasAdd\n",
            "OP=BiasAdd\n",
            "Name=model/29/BiasAdd\n",
            "Inputs:\n",
            "\tmodel/29/MatMul:0=MatMul, [-1, 10], 1\n",
            "\tmodel/29/BiasAdd/ReadVariableOp:0=Const, [10], 1\n",
            "Outpus:\n",
            "\tmodel/29/BiasAdd:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: model/output_0/Relu\n",
            "OP=Relu\n",
            "Name=model/output_0/Relu\n",
            "Inputs:\n",
            "\tmodel/29/BiasAdd:0=Add, [-1, 10], 1\n",
            "Outpus:\n",
            "\tmodel/output_0/Relu:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: Identity\n",
            "OP=Identity\n",
            "Name=Identity\n",
            "Inputs:\n",
            "\tmodel/output_0/Relu:0=Relu, [-1, 10], 1\n",
            "Outpus:\n",
            "\tIdentity_raw_output___12:0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:Process node: Identity_graph_outputs_Identity__13\n",
            "OP=Identity\n",
            "Name=Identity_graph_outputs_Identity__13\n",
            "Inputs:\n",
            "\tIdentity_raw_output___12:0=Identity, [-1, 10], 1\n",
            "Outpus:\n",
            "\toutput_0=[-1, 10], 1\n",
            "DEBUG:tf2onnx.tfonnx:explicitly skip node Identity_graph_outputs_Identity__13\n",
            "VERBOSE:tf2onnx.tfonnx:Summay Stats:\n",
            "\ttensorflow ops: Counter({'Const': 15, 'BiasAdd': 5, 'Relu': 5, 'MatMul': 3, 'Conv2D': 2, 'MaxPool': 2, 'Placeholder': 1, 'Transpose': 1, 'Shape': 1, 'StridedSlice': 1, 'Pack': 1, 'Reshape': 1, 'Identity': 1})\n",
            "\ttensorflow attr: Counter({'T': 46, 'dtype': 32, 'value': 30, 'data_format': 18, 'strides': 8, 'explicit_paddings': 8, 'padding': 8, 'transpose_b': 6, 'transpose_a': 6, 'dilations': 4, 'use_cudnn_on_gpu': 4, 'ksize': 4, 'shape': 2, 'Tperm': 2, 'out_type': 2, 'end_mask': 2, 'shrink_axis_mask': 2, 'begin_mask': 2, 'Index': 2, 'new_axis_mask': 2, 'ellipsis_mask': 2, 'axis': 2, 'N': 2, 'Tshape': 2})\n",
            "\tonnx mapped: Counter({'Const': 11, 'Relu': 5, 'MatMul': 3, 'BiasAdd': 3, 'Conv2D': 2, 'MaxPool': 2, 'Placeholder': 1, 'Transpose': 1, 'Identity': 1})\n",
            "\tonnx unmapped: Counter()\n",
            "INFO:tf2onnx.optimizer:Optimizing ONNX model\n",
            "VERBOSE:tf2onnx.optimizer:Apply optimize_transpose\n",
            "DEBUG:tf2onnx.optimizer.TransposeOptimizer:finish after 6 iteration(s)\n",
            "DEBUG:tf2onnx.graph:Making node: Name=new_shape__33, OP=Const\n",
            "DEBUG:tf2onnx.graph:Made node: new_shape__33\n",
            "OP=Const\n",
            "Name=new_shape__33\n",
            "Outpus:\n",
            "\tnew_shape__33=None, 7\n",
            "DEBUG:tf2onnx.graph:Making node: Name=model/11/BiasAdd__17, OP=Reshape\n",
            "DEBUG:tf2onnx.graph:Made node: model/11/BiasAdd__17\n",
            "OP=Reshape\n",
            "Name=model/11/BiasAdd__17\n",
            "Inputs:\n",
            "\tinput_0=Placeholder, [-1, 28, 28, 1], 1\n",
            "\tnew_shape__33=Const, [4], 7\n",
            "Outpus:\n",
            "\tmodel/11/BiasAdd__17:0=[-1, 1, 28, 28], 1\n",
            "VERBOSE:tf2onnx.optimizer.TransposeOptimizer:Reshape +1 (0->1), Transpose -9 (9->0)\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_redundant_upsample\n",
            "VERBOSE:tf2onnx.optimizer.UpsampleOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply fold_constants\n",
            "VERBOSE:tf2onnx.optimizer.ConstFoldOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply const_dequantize_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ConstDequantizeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply loop_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.LoopOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply merge_duplication\n",
            "VERBOSE:tf2onnx.optimizer.MergeDuplicatedNodesOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply reshape_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ReshapeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply global_pool_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.GlobalPoolOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply q_dq_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.QDQOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_identity\n",
            "VERBOSE:tf2onnx.optimizer.IdentityOptimizer:Identity -2 (2->0)\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_back_to_back\n",
            "VERBOSE:tf2onnx.optimizer.BackToBackOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply einsum_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.EinsumOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply optimize_transpose\n",
            "DEBUG:tf2onnx.optimizer.TransposeOptimizer:finish after 0 iteration(s)\n",
            "VERBOSE:tf2onnx.optimizer.TransposeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_redundant_upsample\n",
            "VERBOSE:tf2onnx.optimizer.UpsampleOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply fold_constants\n",
            "VERBOSE:tf2onnx.optimizer.ConstFoldOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply const_dequantize_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ConstDequantizeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply loop_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.LoopOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply merge_duplication\n",
            "VERBOSE:tf2onnx.optimizer.MergeDuplicatedNodesOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply reshape_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.ReshapeOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply global_pool_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.GlobalPoolOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply q_dq_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.QDQOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_identity\n",
            "VERBOSE:tf2onnx.optimizer.IdentityOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply remove_back_to_back\n",
            "VERBOSE:tf2onnx.optimizer.BackToBackOptimizer:no change\n",
            "VERBOSE:tf2onnx.optimizer:Apply einsum_optimizer\n",
            "VERBOSE:tf2onnx.optimizer.EinsumOptimizer:no change\n",
            "INFO:tf2onnx.optimizer:After optimization: Identity -2 (2->0), Reshape +1 (0->1), Transpose -9 (9->0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEA85J9sy5u1"
      },
      "source": [
        "onnx_model_22 = onnx.load('model_ft-{}2.onnx'.format(model_name))\n",
        "onnx.checker.check_model(onnx_model_22)\n",
        "ort_session22 = onnxruntime.InferenceSession('model_ft-{}2.onnx'.format(model_name))\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs22 = {ort_session22.get_inputs()[0].name: to_numpy(x).reshape(-1,28,28,1)}\n",
        "ort_outs22 = ort_session22.run(None, ort_inputs22)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xojHQBFwy57v",
        "outputId": "a7e627ea-24d9-4551-cc02-69c30dc8a13a"
      },
      "source": [
        "!pip install onnx-pytorch"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx-pytorch in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (from onnx-pytorch) (1.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from onnx-pytorch) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnx-pytorch) (1.19.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (from onnx-pytorch) (1.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-pytorch) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-pytorch) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime->onnx-pytorch) (1.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERq2hEEfy6Fo",
        "outputId": "0155c0ee-a3de-4e6d-fa2b-0d14dd680aaa"
      },
      "source": [
        "from onnx_pytorch import code_gen\n",
        "code_gen.gen(\"/content/model_ft-{}2.onnx\".format(model_name), \"/content\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Tensor name input_0 is changed to t_input_0.\n",
            "WARNING:root:Tensor name new_shape__33 is changed to t_new_shape__33.\n",
            "WARNING:root:Tensor name model/11/BiasAdd__17:0 is changed to t_model_11_BiasAdd__17_0.\n",
            "WARNING:root:Node name model/11/BiasAdd__17 is changed to n_model_11_BiasAdd__17.\n",
            "WARNING:root:Tensor name model/11/BiasAdd__17:0 is changed to t_model_11_BiasAdd__17_0.\n",
            "WARNING:root:Tensor name model/11/Conv2D/ReadVariableOp:0 is changed to t_model_11_Conv2D_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/11/BiasAdd/ReadVariableOp:0 is changed to t_model_11_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/11/BiasAdd:0 is changed to t_model_11_BiasAdd_0.\n",
            "WARNING:root:Node name model/11/BiasAdd is changed to n_model_11_BiasAdd.\n",
            "WARNING:root:Tensor name model/11/BiasAdd:0 is changed to t_model_11_BiasAdd_0.\n",
            "WARNING:root:Tensor name model/12/Relu:0 is changed to t_model_12_Relu_0.\n",
            "WARNING:root:Node name model/12/Relu is changed to n_model_12_Relu.\n",
            "WARNING:root:Tensor name model/12/Relu:0 is changed to t_model_12_Relu_0.\n",
            "WARNING:root:Tensor name model/13/MaxPool:0 is changed to t_model_13_MaxPool_0.\n",
            "WARNING:root:Node name model/13/MaxPool is changed to n_model_13_MaxPool.\n",
            "WARNING:root:Tensor name model/13/MaxPool:0 is changed to t_model_13_MaxPool_0.\n",
            "WARNING:root:Tensor name model/14/Conv2D/ReadVariableOp:0 is changed to t_model_14_Conv2D_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/14/BiasAdd/ReadVariableOp:0 is changed to t_model_14_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/14/BiasAdd:0 is changed to t_model_14_BiasAdd_0.\n",
            "WARNING:root:Node name model/14/BiasAdd is changed to n_model_14_BiasAdd.\n",
            "WARNING:root:Tensor name model/14/BiasAdd:0 is changed to t_model_14_BiasAdd_0.\n",
            "WARNING:root:Tensor name model/15/Relu:0 is changed to t_model_15_Relu_0.\n",
            "WARNING:root:Node name model/15/Relu is changed to n_model_15_Relu.\n",
            "WARNING:root:Tensor name model/15/Relu:0 is changed to t_model_15_Relu_0.\n",
            "WARNING:root:Tensor name model/16/MaxPool:0 is changed to t_model_16_MaxPool_0.\n",
            "WARNING:root:Node name model/16/MaxPool is changed to n_model_16_MaxPool.\n",
            "WARNING:root:Tensor name model/16/MaxPool:0 is changed to t_model_16_MaxPool_0.\n",
            "WARNING:root:Tensor name Flatten__15:0 is changed to t_Flatten__15_0.\n",
            "WARNING:root:Node name Flatten__15 is changed to n_Flatten__15.\n",
            "WARNING:root:Tensor name Flatten__15:0 is changed to t_Flatten__15_0.\n",
            "WARNING:root:Tensor name model/25/MatMul/ReadVariableOp:0 is changed to t_model_25_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/25/MatMul:0 is changed to t_model_25_MatMul_0.\n",
            "WARNING:root:Node name model/25/MatMul is changed to n_model_25_MatMul.\n",
            "WARNING:root:Tensor name model/25/MatMul:0 is changed to t_model_25_MatMul_0.\n",
            "WARNING:root:Tensor name model/25/BiasAdd/ReadVariableOp:0 is changed to t_model_25_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/25/BiasAdd:0 is changed to t_model_25_BiasAdd_0.\n",
            "WARNING:root:Node name model/25/BiasAdd is changed to n_model_25_BiasAdd.\n",
            "WARNING:root:Tensor name model/25/BiasAdd:0 is changed to t_model_25_BiasAdd_0.\n",
            "WARNING:root:Tensor name model/26/Relu:0 is changed to t_model_26_Relu_0.\n",
            "WARNING:root:Node name model/26/Relu is changed to n_model_26_Relu.\n",
            "WARNING:root:Tensor name model/26/Relu:0 is changed to t_model_26_Relu_0.\n",
            "WARNING:root:Tensor name model/27/MatMul/ReadVariableOp:0 is changed to t_model_27_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/27/MatMul:0 is changed to t_model_27_MatMul_0.\n",
            "WARNING:root:Node name model/27/MatMul is changed to n_model_27_MatMul.\n",
            "WARNING:root:Tensor name model/27/MatMul:0 is changed to t_model_27_MatMul_0.\n",
            "WARNING:root:Tensor name model/27/BiasAdd/ReadVariableOp:0 is changed to t_model_27_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/27/BiasAdd:0 is changed to t_model_27_BiasAdd_0.\n",
            "WARNING:root:Node name model/27/BiasAdd is changed to n_model_27_BiasAdd.\n",
            "WARNING:root:Tensor name model/27/BiasAdd:0 is changed to t_model_27_BiasAdd_0.\n",
            "WARNING:root:Tensor name model/28/Relu:0 is changed to t_model_28_Relu_0.\n",
            "WARNING:root:Node name model/28/Relu is changed to n_model_28_Relu.\n",
            "WARNING:root:Tensor name model/28/Relu:0 is changed to t_model_28_Relu_0.\n",
            "WARNING:root:Tensor name model/29/MatMul/ReadVariableOp:0 is changed to t_model_29_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/29/MatMul:0 is changed to t_model_29_MatMul_0.\n",
            "WARNING:root:Node name model/29/MatMul is changed to n_model_29_MatMul.\n",
            "WARNING:root:Tensor name model/29/MatMul:0 is changed to t_model_29_MatMul_0.\n",
            "WARNING:root:Tensor name model/29/BiasAdd/ReadVariableOp:0 is changed to t_model_29_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name model/29/BiasAdd:0 is changed to t_model_29_BiasAdd_0.\n",
            "WARNING:root:Node name model/29/BiasAdd is changed to n_model_29_BiasAdd.\n",
            "WARNING:root:Tensor name model/29/BiasAdd:0 is changed to t_model_29_BiasAdd_0.\n",
            "WARNING:root:Tensor name output_0 is changed to t_output_0.\n",
            "WARNING:root:Node name model/output_0/Relu is changed to n_model_output_0_Relu.\n",
            "WARNING:root:Tensor name t_input_0 is changed to t_input_0.\n",
            "WARNING:root:Tensor name t_output_0 is changed to t_output_0.\n",
            "WARNING:root:Tensor name t_new_shape__33 is changed to t_new_shape__33.\n",
            "WARNING:root:Tensor name t_model_29_MatMul_ReadVariableOp_0 is changed to t_model_29_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_29_BiasAdd_ReadVariableOp_0 is changed to t_model_29_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_27_MatMul_ReadVariableOp_0 is changed to t_model_27_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_27_BiasAdd_ReadVariableOp_0 is changed to t_model_27_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_25_MatMul_ReadVariableOp_0 is changed to t_model_25_MatMul_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_25_BiasAdd_ReadVariableOp_0 is changed to t_model_25_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_14_Conv2D_ReadVariableOp_0 is changed to t_model_14_Conv2D_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_14_BiasAdd_ReadVariableOp_0 is changed to t_model_14_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_11_Conv2D_ReadVariableOp_0 is changed to t_model_11_Conv2D_ReadVariableOp_0.\n",
            "WARNING:root:Tensor name t_model_11_BiasAdd_ReadVariableOp_0 is changed to t_model_11_BiasAdd_ReadVariableOp_0.\n",
            "WARNING:root:Cannot get default value for dilations of Conv.\n",
            "WARNING:root:Cannot get default value for kernel_shape of Conv.\n",
            "WARNING:root:Cannot get default value for pads of Conv.\n",
            "WARNING:root:Cannot get default value for strides of Conv.\n",
            "WARNING:root:Cannot get default value for dilations of MaxPool.\n",
            "WARNING:root:Cannot get default value for kernel_shape of MaxPool.\n",
            "WARNING:root:Cannot get default value for pads of MaxPool.\n",
            "WARNING:root:Cannot get default value for strides of MaxPool.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# Autogenerated by onnx-pytorch.\n",
            "\n",
            "import glob\n",
            "import os\n",
            "\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "\n",
            "\n",
            "class Model(nn.Module):\n",
            "  def __init__(self):\n",
            "    super(Model, self).__init__()\n",
            "    self.__vars = nn.ParameterDict()\n",
            "    for b in glob.glob(\n",
            "        os.path.join(os.path.dirname(__file__), \"variables\", \"*.npy\")):\n",
            "      v = torch.from_numpy(np.load(b))\n",
            "      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex\n",
            "      self.__vars[os.path.basename(b)[:-4]] = nn.Parameter(\n",
            "          torch.from_numpy(np.load(b)), requires_grad=requires_grad)\n",
            "    self.n_n_model_11_BiasAdd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 6, 'padding': 0, 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1, 'bias': True})\n",
            "    self.n_n_model_11_BiasAdd.weight.data = self.__vars[\"t_model_11_Conv2D_ReadVariableOp_0\"]\n",
            "    self.n_n_model_11_BiasAdd.bias.data = self.__vars[\"t_model_11_BiasAdd_ReadVariableOp_0\"]\n",
            "    self.n_n_model_13_MaxPool = nn.MaxPool2d(**{'dilation': 1, 'kernel_size': [2, 2], 'ceil_mode': False, 'stride': [2, 2], 'return_indices': False})\n",
            "    self.n_n_model_14_BiasAdd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': 0, 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 6, 'bias': True})\n",
            "    self.n_n_model_14_BiasAdd.weight.data = self.__vars[\"t_model_14_Conv2D_ReadVariableOp_0\"]\n",
            "    self.n_n_model_14_BiasAdd.bias.data = self.__vars[\"t_model_14_BiasAdd_ReadVariableOp_0\"]\n",
            "    self.n_n_model_16_MaxPool = nn.MaxPool2d(**{'dilation': 1, 'kernel_size': [2, 2], 'ceil_mode': False, 'stride': [2, 2], 'return_indices': False})\n",
            "    self.n_n_Flatten__15 = nn.Flatten(**{'start_dim': 1})\n",
            "\n",
            "  def forward(self, *inputs):\n",
            "    t_input_0, = inputs\n",
            "    shape_t_input_0 = [s if s != 0 else t_input_0.shape[i] for i, s in enumerate(self.__vars[\"t_new_shape__33\"])]\n",
            "    t_model_11_BiasAdd__17_0 = torch.reshape(t_input_0, shape_t_input_0)\n",
            "    t_model_11_BiasAdd_0 = self.n_n_model_11_BiasAdd(t_model_11_BiasAdd__17_0)\n",
            "    t_model_12_Relu_0 = F.relu(t_model_11_BiasAdd_0)\n",
            "    t_model_13_MaxPool_0 = self.n_n_model_13_MaxPool(t_model_12_Relu_0)\n",
            "    t_model_14_BiasAdd_0 = self.n_n_model_14_BiasAdd(t_model_13_MaxPool_0)\n",
            "    t_model_15_Relu_0 = F.relu(t_model_14_BiasAdd_0)\n",
            "    t_model_16_MaxPool_0 = self.n_n_model_16_MaxPool(t_model_15_Relu_0)\n",
            "    t_Flatten__15_0 = self.n_n_Flatten__15(t_model_16_MaxPool_0)\n",
            "    t_model_25_MatMul_0 = torch.matmul(t_Flatten__15_0, self.__vars[\"t_model_25_MatMul_ReadVariableOp_0\"])\n",
            "    t_model_25_BiasAdd_0 = t_model_25_MatMul_0 + self.__vars[\"t_model_25_BiasAdd_ReadVariableOp_0\"]\n",
            "    t_model_26_Relu_0 = F.relu(t_model_25_BiasAdd_0)\n",
            "    t_model_27_MatMul_0 = torch.matmul(t_model_26_Relu_0, self.__vars[\"t_model_27_MatMul_ReadVariableOp_0\"])\n",
            "    t_model_27_BiasAdd_0 = t_model_27_MatMul_0 + self.__vars[\"t_model_27_BiasAdd_ReadVariableOp_0\"]\n",
            "    t_model_28_Relu_0 = F.relu(t_model_27_BiasAdd_0)\n",
            "    t_model_29_MatMul_0 = torch.matmul(t_model_28_Relu_0, self.__vars[\"t_model_29_MatMul_ReadVariableOp_0\"])\n",
            "    t_model_29_BiasAdd_0 = t_model_29_MatMul_0 + self.__vars[\"t_model_29_BiasAdd_ReadVariableOp_0\"]\n",
            "    t_output_0 = F.relu(t_model_29_BiasAdd_0)\n",
            "    return t_output_0\n",
            "\n",
            "\n",
            "@torch.no_grad()\n",
            "def test_run_model(inputs=[torch.from_numpy(np.random.randn(*[1, 28, 28, 1]).astype(np.float32))]):\n",
            "  model = Model()\n",
            "  model.eval()\n",
            "  print(model)\n",
            "  rs = model(*inputs)\n",
            "  print(rs)\n",
            "  return rs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibuhcpiqy6h6",
        "outputId": "706d8dd7-90dc-468a-bcb4-3fc426d10fd0"
      },
      "source": [
        "onnx_model_tf = onnx.load('/content/model_ft-{}2.onnx'.format(model_name))\n",
        "tf_rep = prepare(onnx_model_tf)  # prepare tf representation\n",
        "tf_rep.inputs"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-QlzsZo2HTH"
      },
      "source": [
        "import numpy as np\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import torch\n",
        "\n",
        "torch.set_printoptions(8)\n",
        "\n",
        "from model import Model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfOn50Bi2Hge",
        "outputId": "3474db86-1316-4524-d3e6-0f5227d8d46b"
      },
      "source": [
        "np.random.seed(42)\n",
        "model = Model()\n",
        "model.eval()\n",
        "#inp = np.random.randn(batch_size, 1, 28, 28).astype(np.float32)\n",
        "torch.random.manual_seed(42)\n",
        "x = torch.randn(batch_size, 1, 28, 28, requires_grad=True)\n",
        "#torch_out = model_ft(x)\n",
        "\n",
        "with torch.no_grad():\n",
        "  #torch_outputs = model(torch.from_numpy(inp))\n",
        "  torch_outputs = model(x)\n",
        "  \n",
        "\n",
        "onnx_model = onnx.load(\"/content/model_ft-{}2.onnx\".format(model_name))\n",
        "sess_options = onnxruntime.SessionOptions()\n",
        "session = onnxruntime.InferenceSession(onnx_model.SerializeToString(),\n",
        "                                       sess_options)\n",
        "#print(session.get_inputs)\n",
        "\n",
        "ort_session2 = onnxruntime.InferenceSession('model_ft_keras-{}2.onnx'.format(model_name))\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session2.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outputs = ort_session2.run(None, ort_inputs)\n",
        "\n",
        "print(\n",
        "    \"Comparison result:\",\n",
        "    np.allclose(torch_outputs.detach().numpy(),\n",
        "                ort_outputs[0],\n",
        "                atol=1e-5,\n",
        "                rtol=1e-5))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparison result: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "dPWAhoG52HmF",
        "outputId": "5d0d62c9-ef1b-47f9-9014-603b230862df"
      },
      "source": [
        "np.testing.assert_array_equal(torch_outputs.detach().numpy(), ort_outputs[0])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-3c991d600d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_equal\u001b[0;34m(x, y, err_msg, verbose)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Hide traceback for py.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n\u001b[0;32m--> 931\u001b[0;31m                          verbose=verbose, header='Arrays are not equal')\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not equal\n\nMismatched elements: 255 / 2560 (9.96%)\nMax absolute difference: 21.306751\nMax relative difference: 136.99713\n x: array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],...\n y: array([[0.      , 0.264218, 0.      , ..., 0.      , 0.      , 0.      ],\n       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n       [1.261286, 0.      , 0.      , ..., 0.      , 0.193427, 0.      ],..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vRZvmuW2IE_",
        "outputId": "e66618ed-93c0-48cf-9087-974fec6c8e6d"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     || 46.9 MB 39 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVguOUVn2IQJ"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import mxnet.contrib.onnx as onnx_mxnet\n",
        "from mxnet.test_utils import download\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "LvpkfQRC2IWg",
        "outputId": "3fbbbd30-c9e9-4e7a-aba9-998926b1eff7"
      },
      "source": [
        "#onnx_model_file = mxnet(model_url, '/content/model_ft-{}2.onnx')\n",
        "sym, arg_params, aux_params = onnx_mxnet.import_model(\"/content/model_ft-{}2.onnx\".format(model_name))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-6b2068fd5542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#onnx_model_file = mxnet(model_url, '/content/model_ft-{}2.onnx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_mxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/model_ft-{}2.onnx\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mxnet/contrib/onnx/onnx2mx/import_model.py\u001b[0m in \u001b[0;36mimport_model\u001b[0;34m(model_file)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mmodel_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmodel_opset_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopset_import\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_opset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mxnet/contrib/onnx/onnx2mx/import_onnx.py\u001b[0m in \u001b[0;36mfrom_onnx\u001b[0;34m(self, graph, opset_version)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mnode_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0monnx_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mmxnet_sym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mxnet/contrib/onnx/onnx2mx/import_onnx.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mnode_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0monnx_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mmxnet_sym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'new_shape__33'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCmIYLWwG-Ou"
      },
      "source": [
        "mx.viz.plot_network(sym, node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixKViRYaG-Vv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7b_tqWyG-bJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5OerWZG-h-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX1eMQv7G-m6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}