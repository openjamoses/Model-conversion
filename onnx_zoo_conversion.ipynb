{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "onnx-zoo-conversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqav7+JWY0ZveuyWJmjUL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "167192e5d1fd415d989e95d33100f7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8df5aab4e8149eab354b08be139a99b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85cb166f617b47ef9ef3a8971b34dcf1",
              "IPY_MODEL_ac0b26a5eaef4ef8a728ad580d106034"
            ]
          }
        },
        "f8df5aab4e8149eab354b08be139a99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85cb166f617b47ef9ef3a8971b34dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d32413f04b8e42f09cecfbeb695fb050",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04c14240f28a4c8495224be76b88045a"
          }
        },
        "ac0b26a5eaef4ef8a728ad580d106034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0dcc5ffb0a64a8ab22c3a1e1f366839",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [06:56&lt;00:00, 23781.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17f638b2093d4dc9ae3d456ba84b9528"
          }
        },
        "d32413f04b8e42f09cecfbeb695fb050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04c14240f28a4c8495224be76b88045a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0dcc5ffb0a64a8ab22c3a1e1f366839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17f638b2093d4dc9ae3d456ba84b9528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c69bc8aa8a194596878b99d179f86f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0480efed6b745aa8c35d8e955f02284",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81dc2aa0c33641aa83f1401b80f8eecb",
              "IPY_MODEL_0b472444ec584344b86629b1c3c6c1bd"
            ]
          }
        },
        "e0480efed6b745aa8c35d8e955f02284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81dc2aa0c33641aa83f1401b80f8eecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4bdfa673862149069fcd4e6d356eec11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20b804d148e74a3eadc30a1c0c592783"
          }
        },
        "0b472444ec584344b86629b1c3c6c1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83a90f8a0ec64c8985d717821e564802",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:50&lt;00:00, 593.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f250d1918c9456480ca6b06d9c3c34a"
          }
        },
        "4bdfa673862149069fcd4e6d356eec11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20b804d148e74a3eadc30a1c0c592783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83a90f8a0ec64c8985d717821e564802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f250d1918c9456480ca6b06d9c3c34a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33a55060614f48cbbcf4d1a86f6197d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be52f2ea47424510b103301048a6e17f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d89982afd41f411e832a5dfab8ee6af5",
              "IPY_MODEL_b8c23ffa749f46afadc7d62a56952c29"
            ]
          }
        },
        "be52f2ea47424510b103301048a6e17f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d89982afd41f411e832a5dfab8ee6af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdb8b2594e7b4795b5e2c3e9279e652a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4e6bf2559234507bc2b8fc68e3369e6"
          }
        },
        "b8c23ffa749f46afadc7d62a56952c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0ca202338a046ffb3da0cbbf648c273",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:49&lt;00:00, 33620.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61dd40760df24ad6a87df9eb0097dd76"
          }
        },
        "cdb8b2594e7b4795b5e2c3e9279e652a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4e6bf2559234507bc2b8fc68e3369e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0ca202338a046ffb3da0cbbf648c273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61dd40760df24ad6a87df9eb0097dd76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7ae6abe29ed40aab532a1fe41fe0c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_564f61fae9f14cb9a8fbe9a8d1904f3c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4c6f0585c5548a4824649ad4565c23f",
              "IPY_MODEL_36280a5c62174723a71b41edbb7e1a04"
            ]
          }
        },
        "564f61fae9f14cb9a8fbe9a8d1904f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4c6f0585c5548a4824649ad4565c23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49273a5587f04b90a990887cfafef831",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b6befdefee64fa496d62efcd1f447e5"
          }
        },
        "36280a5c62174723a71b41edbb7e1a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00f57c5014ce4931819475e6dd3180d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [01:02&lt;00:00, 81.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1725f07274654f658a7a4232fd3b8199"
          }
        },
        "49273a5587f04b90a990887cfafef831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b6befdefee64fa496d62efcd1f447e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00f57c5014ce4931819475e6dd3180d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1725f07274654f658a7a4232fd3b8199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09c2cbb4774144c18209583785b90a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9a6628b45dd48488ece19aa2d14e2e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a345642c29264c17a3535a78f0e2d02b",
              "IPY_MODEL_8453826b5e43409abe1fcb7748b1e2b3"
            ]
          }
        },
        "f9a6628b45dd48488ece19aa2d14e2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a345642c29264c17a3535a78f0e2d02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e202a5fc4f5e4b0aaee2167e14b8a5d3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aae0dbe095142b09bf4a74816178369"
          }
        },
        "8453826b5e43409abe1fcb7748b1e2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ccfab1c81e274cbba2de6b1ff384a368",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [12:48&lt;00:00, 60.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72825ce3b5804a4f806660946f598d0c"
          }
        },
        "e202a5fc4f5e4b0aaee2167e14b8a5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aae0dbe095142b09bf4a74816178369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccfab1c81e274cbba2de6b1ff384a368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72825ce3b5804a4f806660946f598d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/openjamoses/Model-conversion/blob/main/onnx_zoo_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "245U54ZjKcPx",
        "outputId": "f3db1581-b16d-45ca-b547-ad4291dfbc68"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip uninstall onnx"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "\u001b[33mWARNING: Skipping onnx as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HIxjFV0Ll7s"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install onnx==1.8.1\n",
        "!pip install onnx_tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abk-LFEHLmGY",
        "outputId": "1cbeb002-52f9-48f2-a420-1b1b7a796625"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUDrPhU0LmKk"
      },
      "source": [
        "#Import needed packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPxaXEr7LmOJ",
        "outputId": "9aa01b5a-c85b-49e4-80ef-968f935f756d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_output = \"/content/drive/MyDrive/Colab Notebooks/models/torch/save/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhA2OFtaLmRL"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq50Vss4LmUM"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1emAkQTMmxt"
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        " \n",
        "    test_loss /= len(test_loader.dataset)\n",
        " \n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "167192e5d1fd415d989e95d33100f7c2",
            "f8df5aab4e8149eab354b08be139a99b",
            "85cb166f617b47ef9ef3a8971b34dcf1",
            "ac0b26a5eaef4ef8a728ad580d106034",
            "d32413f04b8e42f09cecfbeb695fb050",
            "04c14240f28a4c8495224be76b88045a",
            "b0dcc5ffb0a64a8ab22c3a1e1f366839",
            "17f638b2093d4dc9ae3d456ba84b9528",
            "c69bc8aa8a194596878b99d179f86f1a",
            "e0480efed6b745aa8c35d8e955f02284",
            "81dc2aa0c33641aa83f1401b80f8eecb",
            "0b472444ec584344b86629b1c3c6c1bd",
            "4bdfa673862149069fcd4e6d356eec11",
            "20b804d148e74a3eadc30a1c0c592783",
            "83a90f8a0ec64c8985d717821e564802",
            "0f250d1918c9456480ca6b06d9c3c34a",
            "33a55060614f48cbbcf4d1a86f6197d0",
            "be52f2ea47424510b103301048a6e17f",
            "d89982afd41f411e832a5dfab8ee6af5",
            "b8c23ffa749f46afadc7d62a56952c29",
            "cdb8b2594e7b4795b5e2c3e9279e652a",
            "e4e6bf2559234507bc2b8fc68e3369e6",
            "a0ca202338a046ffb3da0cbbf648c273",
            "61dd40760df24ad6a87df9eb0097dd76",
            "b7ae6abe29ed40aab532a1fe41fe0c2b",
            "564f61fae9f14cb9a8fbe9a8d1904f3c",
            "d4c6f0585c5548a4824649ad4565c23f",
            "36280a5c62174723a71b41edbb7e1a04",
            "49273a5587f04b90a990887cfafef831",
            "6b6befdefee64fa496d62efcd1f447e5",
            "00f57c5014ce4931819475e6dd3180d0",
            "1725f07274654f658a7a4232fd3b8199"
          ]
        },
        "id": "vNOJyzSwMm2p",
        "outputId": "24264848-6eed-412d-9c08-9cd8c45e272f"
      },
      "source": [
        "#def main():\n",
        "device =  \"cpu\"\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "batch_size=1000, shuffle=True)\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        " \n",
        "for epoch in range(0, 5): \n",
        "  train(model, device, train_loader, optimizer, epoch) \n",
        "  test(model, device, test_loader)\n",
        "torch.save(model.state_dict(),path_output+\"model.pt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "167192e5d1fd415d989e95d33100f7c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c69bc8aa8a194596878b99d179f86f1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33a55060614f48cbbcf4d1a86f6197d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7ae6abe29ed40aab532a1fe41fe0c2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.310008\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.401208\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.319989\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.159391\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.131457\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.143643\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.217413\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.112390\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.067025\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.041402\n",
            "\n",
            "Test set: Average loss: 0.0956, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.063342\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.034307\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.131638\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.085060\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.020943\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.088812\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.015732\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.025499\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.053336\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.030135\n",
            "\n",
            "Test set: Average loss: 0.0590, Accuracy: 9812/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.074578\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.031979\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.197539\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.027075\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.167608\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.069909\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.094254\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.050182\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.046670\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.022050\n",
            "\n",
            "Test set: Average loss: 0.0491, Accuracy: 9849/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.030784\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.012672\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.015100\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.009207\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.083707\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.050970\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.037856\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.006630\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.078829\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.099828\n",
            "\n",
            "Test set: Average loss: 0.0454, Accuracy: 9846/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012774\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.083431\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.047091\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.057499\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.018182\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.014765\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.050191\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.017744\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.035419\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.088550\n",
            "\n",
            "Test set: Average loss: 0.0362, Accuracy: 9884/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wnr415EMm7S"
      },
      "source": [
        "!pip install pytorch2keras\n",
        "#!pip install onnx==1.8.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZb3FTqaMnNd"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEfeRqb0MnSi"
      },
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "#hymenoptera_data.zip"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nglMifePo-g"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/hymenoptera_data.zip' -d '/content'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKvF_7wDPpG5",
        "outputId": "75e996ca-a057-47a5-fb6e-3717576187e6"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "BouYxa8SPpLZ",
        "outputId": "78b71af4-7c52-40cd-b937-ab0fb4136495"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "244Ny5-YPpOt"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpbb0vQ4PpT-"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "\n",
        "    data_file = open('/content/experiment_train_{}.csv'.format(date), mode='w+', newline='', encoding='utf-8')\n",
        "    data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\", 'time','Elapse_time','date'])\n",
        "\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        since_1 = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        #data_writer.writerow(['Model','type', 'Dataset', 'Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\"])\n",
        "        rows = [model, 'pytorch','hymenoptera_data','{}/{}'.format(epoch, num_epochs - 1) ,criterion, optimizer, scheduler]\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            rows.append(phase)\n",
        "            rows.append('Loss: {:.4f}'.format(epoch_loss))\n",
        "            rows.append('Acc: {:.4f}'.format(epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        time_elapsed_1 = time.time() - since_1\n",
        "        print()\n",
        "        rows.append(time.time())\n",
        "        rows.append('{:.0f}m {:.0f}s'.format(time_elapsed_1 // 60, time_elapsed_1 % 60))\n",
        "        data_writer.writerow(rows)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    data_writer.writerow(['','', '', '', '', '', \"\", 'Best val Acc: {:4f}'.format(best_acc), time.time(),'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),''])\n",
        "\n",
        "    data_file.close()\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2v2CkmgPpaf"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "09c2cbb4774144c18209583785b90a26",
            "f9a6628b45dd48488ece19aa2d14e2e1",
            "a345642c29264c17a3535a78f0e2d02b",
            "8453826b5e43409abe1fcb7748b1e2b3",
            "e202a5fc4f5e4b0aaee2167e14b8a5d3",
            "3aae0dbe095142b09bf4a74816178369",
            "ccfab1c81e274cbba2de6b1ff384a368",
            "72825ce3b5804a4f806660946f598d0c"
          ]
        },
        "id": "pkOxEqIePpgQ",
        "outputId": "e6cff3ce-8c13-46e6-e1d5-e167d923d356"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c2cbb4774144c18209583785b90a26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjYC5oLkQ6MP",
        "outputId": "5dd30e40-a558-423e-fece-0bb2fa5744c1"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5514 Acc: 0.7582\n",
            "val Loss: 0.3222 Acc: 0.8889\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.4795 Acc: 0.7951\n",
            "val Loss: 0.5027 Acc: 0.7974\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.4819 Acc: 0.8156\n",
            "val Loss: 0.2879 Acc: 0.8758\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.4703 Acc: 0.7828\n",
            "val Loss: 0.1802 Acc: 0.9281\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.3770 Acc: 0.8443\n",
            "val Loss: 0.2640 Acc: 0.9216\n",
            "\n",
            "Training complete in 7m 3s\n",
            "Best val Acc: 0.928105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-3cBJP-Q6RM"
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lE9CeRQQ6Vp",
        "outputId": "711acba1-643c-48bd-fd37-6aa624dba6fc"
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7184 Acc: 0.5943\n",
            "val Loss: 0.5149 Acc: 0.7712\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.5108 Acc: 0.7828\n",
            "val Loss: 0.1919 Acc: 0.9346\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.4132 Acc: 0.8197\n",
            "val Loss: 0.2196 Acc: 0.9346\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.4033 Acc: 0.8443\n",
            "val Loss: 0.1784 Acc: 0.9542\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.4847 Acc: 0.7869\n",
            "val Loss: 0.1742 Acc: 0.9412\n",
            "\n",
            "Training complete in 3m 13s\n",
            "Best val Acc: 0.954248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X96glEvyQ6aZ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from pytorch2keras.converter import pytorch_to_keras\n",
        "import torchvision.models as models"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BzhZUwQ6ey",
        "outputId": "0e31dc34-0ff0-44cd-c1ef-bf6e25eb7e5e"
      },
      "source": [
        "input_np = np.random.uniform(0, 1, (1, 3, 224, 224))\n",
        "input_var = Variable(torch.FloatTensor(input_np))\n",
        "k_model_model_conv = pytorch_to_keras(model_conv, input_var, [(3, 224, 224,)], verbose=True, change_ordering=True)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch2keras:Converter is called.\n",
            "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
            "DEBUG:pytorch2keras:Input_names:\n",
            "DEBUG:pytorch2keras:['input_0']\n",
            "DEBUG:pytorch2keras:Output_names:\n",
            "DEBUG:pytorch2keras:['output_0']\n",
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:[(3, 224, 224)]\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> input_0.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> output_0.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight fc.weight with shape (2, 512).\n",
            "DEBUG:onnx2keras:Found weight fc.bias with shape (2,).\n",
            "DEBUG:onnx2keras:Found weight 193 with shape (64, 3, 7, 7).\n",
            "DEBUG:onnx2keras:Found weight 194 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 196 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 197 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 199 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 200 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 202 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 203 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 205 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 206 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 208 with shape (128, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 209 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 211 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 212 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 214 with shape (128, 64, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 215 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 217 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 218 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 220 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 221 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 223 with shape (256, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 224 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 226 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 227 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 229 with shape (256, 128, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 230 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 232 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 233 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 235 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 236 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 238 with shape (512, 256, 3, 3).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "graph(%input_0 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
            "      %fc.weight : Float(2, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
            "      %fc.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
            "      %193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
            "      %194 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %196 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %197 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %199 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %200 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %202 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %203 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %205 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %206 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %208 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %209 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %211 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %212 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %214 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %215 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %217 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %218 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %220 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %221 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %223 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %224 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %226 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %227 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %229 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %230 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %232 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %233 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %235 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %236 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %238 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %239 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %241 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %242 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %244 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %245 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %247 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %248 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %250 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %251 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %192 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input_0, %193, %194)\n",
            "  %125 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=0, device=cpu) = onnx::Relu(%192) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %126 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125)\n",
            "  %195 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %196, %197)\n",
            "  %129 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Relu(%195) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %198 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %199, %200)\n",
            "  %132 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Add(%198, %126) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %133 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Relu(%132)\n",
            "  %201 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %202, %203)\n",
            "  %136 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Relu(%201) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %204 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %205, %206)\n",
            "  %139 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Add(%204, %133) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %140 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Relu(%139) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %207 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %208, %209)\n",
            "  %143 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Relu(%207) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %210 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %211, %212)\n",
            "  %213 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %214, %215)\n",
            "  %148 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Add(%210, %213) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %149 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Relu(%148)\n",
            "  %216 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %217, %218)\n",
            "  %152 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Relu(%216) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %219 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %220, %221)\n",
            "  %155 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Add(%219, %149) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %156 : Float(1, 128, 28, 28, strides=[100352, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Relu(%155) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %222 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %223, %224)\n",
            "  %159 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Relu(%222) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %225 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %226, %227)\n",
            "  %228 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %229, %230)\n",
            "  %164 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add(%225, %228) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %165 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Relu(%164)\n",
            "  %231 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %232, %233)\n",
            "  %168 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Relu(%231) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %234 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %235, %236)\n",
            "  %171 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add(%234, %165) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %172 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Relu(%171) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %237 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %238, %239)\n",
            "  %175 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Relu(%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %240 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %241, %242)\n",
            "  %243 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %244, %245)\n",
            "  %180 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Add(%240, %243) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %181 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Relu(%180)\n",
            "  %246 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %247, %248)\n",
            "  %184 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Relu(%246) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %249 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %250, %251)\n",
            "  %187 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Add(%249, %181) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %188 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=0, device=cpu) = onnx::Relu(%187) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %189 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = onnx::GlobalAveragePool(%188) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1130:0\n",
            "  %190 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Flatten[axis=1](%189) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:243:0\n",
            "  %output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%190, %fc.weight, %fc.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1847:0\n",
            "  return (%output_0)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DEBUG:onnx2keras:Found weight 239 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 241 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 242 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 244 with shape (512, 256, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 245 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 247 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 248 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 250 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 251 with shape (512,).\n",
            "DEBUG:onnx2keras:Found input input_0 with shape (3, 224, 224)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 192\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [7, 7], 'pads': [3, 3, 3, 3], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
            "DEBUG:onnx2keras:Check input 1 (name 193).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 194).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 112, 112), dtype=tf.float32, name=None), name='192/BiasAdd:0', description=\"created by layer '192'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 125\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 192).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 112, 112), dtype=tf.float32, name=None), name='125/Relu:0', description=\"created by layer '125'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 126\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 125).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='126/MaxPool:0', description=\"created by layer '126'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 195\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 126).\n",
            "DEBUG:onnx2keras:Check input 1 (name 196).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 197).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='195/BiasAdd:0', description=\"created by layer '195'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 129\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 195).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='129/Relu:0', description=\"created by layer '129'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 198\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 129).\n",
            "DEBUG:onnx2keras:Check input 1 (name 199).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 200).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='198/BiasAdd:0', description=\"created by layer '198'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 132\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 198).\n",
            "DEBUG:onnx2keras:Check input 1 (name 126).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='132/add:0', description=\"created by layer '132'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 133\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 132).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='133/Relu:0', description=\"created by layer '133'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 201\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 133).\n",
            "DEBUG:onnx2keras:Check input 1 (name 202).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 203).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='201/BiasAdd:0', description=\"created by layer '201'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 136\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 201).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='136/Relu:0', description=\"created by layer '136'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 204\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 136).\n",
            "DEBUG:onnx2keras:Check input 1 (name 205).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 206).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='204/BiasAdd:0', description=\"created by layer '204'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 139\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 204).\n",
            "DEBUG:onnx2keras:Check input 1 (name 133).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='139/add:0', description=\"created by layer '139'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 140\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 139).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 56, 56), dtype=tf.float32, name=None), name='140/Relu:0', description=\"created by layer '140'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 207\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 140).\n",
            "DEBUG:onnx2keras:Check input 1 (name 208).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 209).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='207/BiasAdd:0', description=\"created by layer '207'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 143\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 207).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='143/Relu:0', description=\"created by layer '143'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 210\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 143).\n",
            "DEBUG:onnx2keras:Check input 1 (name 211).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 212).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='210/BiasAdd:0', description=\"created by layer '210'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 213\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 140).\n",
            "DEBUG:onnx2keras:Check input 1 (name 214).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 215).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='213/BiasAdd:0', description=\"created by layer '213'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 148\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 210).\n",
            "DEBUG:onnx2keras:Check input 1 (name 213).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='148/add:0', description=\"created by layer '148'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 149\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 148).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='149/Relu:0', description=\"created by layer '149'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 216\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 149).\n",
            "DEBUG:onnx2keras:Check input 1 (name 217).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 218).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='216/BiasAdd:0', description=\"created by layer '216'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 152\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 216).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='152/Relu:0', description=\"created by layer '152'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 219\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 152).\n",
            "DEBUG:onnx2keras:Check input 1 (name 220).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 221).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='219/BiasAdd:0', description=\"created by layer '219'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 155\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 219).\n",
            "DEBUG:onnx2keras:Check input 1 (name 149).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='155/add:0', description=\"created by layer '155'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 156\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 155).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 28, 28), dtype=tf.float32, name=None), name='156/Relu:0', description=\"created by layer '156'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 222\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 156).\n",
            "DEBUG:onnx2keras:Check input 1 (name 223).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 224).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='222/BiasAdd:0', description=\"created by layer '222'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 159\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 222).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='159/Relu:0', description=\"created by layer '159'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 225\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 159).\n",
            "DEBUG:onnx2keras:Check input 1 (name 226).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 227).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='225/BiasAdd:0', description=\"created by layer '225'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 228\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 156).\n",
            "DEBUG:onnx2keras:Check input 1 (name 229).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 230).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='228/BiasAdd:0', description=\"created by layer '228'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 164\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 225).\n",
            "DEBUG:onnx2keras:Check input 1 (name 228).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='164/add:0', description=\"created by layer '164'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 165\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 164).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='165/Relu:0', description=\"created by layer '165'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 231\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 165).\n",
            "DEBUG:onnx2keras:Check input 1 (name 232).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 233).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='231/BiasAdd:0', description=\"created by layer '231'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 168\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 231).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='168/Relu:0', description=\"created by layer '168'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 234\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 168).\n",
            "DEBUG:onnx2keras:Check input 1 (name 235).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 236).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='234/BiasAdd:0', description=\"created by layer '234'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 171\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 234).\n",
            "DEBUG:onnx2keras:Check input 1 (name 165).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='171/add:0', description=\"created by layer '171'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 172\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 171).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 14, 14), dtype=tf.float32, name=None), name='172/Relu:0', description=\"created by layer '172'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 237\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 172).\n",
            "DEBUG:onnx2keras:Check input 1 (name 238).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 239).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='237/BiasAdd:0', description=\"created by layer '237'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 175\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 237).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='175/Relu:0', description=\"created by layer '175'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 240\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 175).\n",
            "DEBUG:onnx2keras:Check input 1 (name 241).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 242).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='240/BiasAdd:0', description=\"created by layer '240'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 243\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 172).\n",
            "DEBUG:onnx2keras:Check input 1 (name 244).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 245).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='243/BiasAdd:0', description=\"created by layer '243'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 180\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 240).\n",
            "DEBUG:onnx2keras:Check input 1 (name 243).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='180/add:0', description=\"created by layer '180'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 181\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 180).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='181/Relu:0', description=\"created by layer '181'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 246\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 181).\n",
            "DEBUG:onnx2keras:Check input 1 (name 247).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 248).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='246/BiasAdd:0', description=\"created by layer '246'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 184\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 246).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='184/Relu:0', description=\"created by layer '184'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 249\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 184).\n",
            "DEBUG:onnx2keras:Check input 1 (name 250).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 251).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='249/BiasAdd:0', description=\"created by layer '249'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 187\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 249).\n",
            "DEBUG:onnx2keras:Check input 1 (name 181).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='187/add:0', description=\"created by layer '187'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 188\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 187).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 7, 7), dtype=tf.float32, name=None), name='188/Relu:0', description=\"created by layer '188'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: GlobalAveragePool\n",
            "DEBUG:onnx2keras:node_name: 189\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 188).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:global_avg_pool:Now expand dimensions twice.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 1, 1), dtype=tf.float32, name=None), name='189_EXPAND2/ExpandDims:0', description=\"created by layer '189_EXPAND2'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Flatten\n",
            "DEBUG:onnx2keras:node_name: 190\n",
            "DEBUG:onnx2keras:node_params: {'axis': 1, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 189).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:flatten:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='190/Reshape:0', description=\"created by layer '190'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: output_0\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 190).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 512, output units 2.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='output_0/BiasAdd:0', description=\"created by layer 'output_0'\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHLSNzjvQ6hd",
        "outputId": "700f8926-3348-4147-99df-ed8ed429f5d1"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir+'/train',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir+'/val',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 245 files belonging to 2 classes.\n",
            "Using 196 files for training.\n",
            "Found 153 files belonging to 2 classes.\n",
            "Using 30 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hztKKkhhU7IP"
      },
      "source": [
        "k_model_model_conv.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Idt8gZU7Xq",
        "outputId": "f4838887-8b8e-4523-a0d9-2a34b9af5578"
      },
      "source": [
        "fit_history_k_model_model_conv = k_model_model_conv.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=5\n",
        ")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7/7 [==============================] - 57s 8s/step - loss: 47.9838 - accuracy: 0.4439 - val_loss: 0.8528 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 54s 7s/step - loss: 12.2423 - accuracy: 0.5561 - val_loss: 2.5622 - val_accuracy: 0.3667\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 53s 7s/step - loss: 1.1884 - accuracy: 0.5153 - val_loss: 0.6197 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 54s 8s/step - loss: 0.7507 - accuracy: 0.5102 - val_loss: 0.7265 - val_accuracy: 0.4000\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 54s 7s/step - loss: 0.7158 - accuracy: 0.4592 - val_loss: 0.6761 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CowoFCipU7b1"
      },
      "source": [
        "def export_history_csv(history_):\n",
        "  since = time.time()\n",
        "  date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "  data_file = open('/content/tensorflow_exp_train_{}.csv'.format(date), mode='w+', newline='', encoding='utf-8')\n",
        "  data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\", 'time','Elapse_time','date'])\n",
        "  for epoch_ in history_.epoch:\n",
        "    data_writer.writerow([history_.model,'tensorflow', 'hymenoptera', epoch_, '', \n",
        "                          history_.model.optimizer, '',history_.history['loss'][epoch_], history_.history['accuracy'][epoch_], \n",
        "                          history_.history['val_loss'][epoch_], history_.history['val_accuracy'][epoch_], '','',date])\n",
        "  data_file.close()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmuBpJd2U7iX"
      },
      "source": [
        "export_history_csv(fit_history_k_model_model_conv)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhCkHqURXKGc"
      },
      "source": [
        "Lets try prediction using pytorch model and keras **model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLutAvfzU7nE",
        "outputId": "33c3ffa4-83e9-4c88-8ffa-89f73ec15afa"
      },
      "source": [
        "i_0 = 0\n",
        "for i, (inputs, labels) in enumerate(dataloaders['train']):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  if i_0 == 0:\n",
        "    torch_images_train = inputs\n",
        "    torch_labels_train = labels\n",
        "  else:\n",
        "    torch_images_train = torch.cat([torch_images_train, inputs], 0)\n",
        "    torch_labels_train = torch.cat([torch_labels_train, labels], 0)\n",
        "  i_0 += 1\n",
        "print(torch_images_train.size(), torch_labels_train.size())\n",
        "\n",
        "i_0 = 0\n",
        "for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  if i_0 == 0:\n",
        "    torch_images_val = inputs\n",
        "    torch_labels_val = labels\n",
        "  else:\n",
        "    torch_images_val = torch.cat([torch_images_val, inputs], 0)\n",
        "    torch_labels_val = torch.cat([torch_labels_val, labels], 0)\n",
        "  i_0 += 1\n",
        "print(torch_images_val.size(), torch_labels_val.size())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([244, 3, 224, 224]) torch.Size([244])\n",
            "torch.Size([153, 3, 224, 224]) torch.Size([153])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go64b51_U7qQ"
      },
      "source": [
        "pred_torch_fit_train = model_ft(torch_images_train)\n",
        "pred_torch_fit_val = model_ft(torch_images_val)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhcKsfUhX1Cn"
      },
      "source": [
        "Lets predict with tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMhIiCmMU72Y"
      },
      "source": [
        "np_tensor = torch_images_train.numpy()\n",
        "tf_tensor_images_train = tf.convert_to_tensor(np_tensor)\n",
        "\n",
        "np_tensor = torch_labels_train.numpy()\n",
        "tf_tensor_labels_train = tf.convert_to_tensor(np_tensor)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktaL9D6VY-3R",
        "outputId": "07184abf-71ae-4e9d-c7a7-c6cde1167b61"
      },
      "source": [
        "input_np = np.random.uniform(0, 1, (1, 3, 180, 180))\n",
        "input_var = Variable(torch.FloatTensor(input_np))\n",
        "#k_model_model_conv2 = pytorch_to_keras(model_conv, input_var, [(3, 180, 180,)], verbose=True, change_ordering=True)\n",
        "#dummy_input = torch.randn(10, 3, 224, 224, device='cpu')\n",
        "#dummy_input = torch.randn(0, 1, (1, 3, 180, 180), device='cpu')\n",
        "#model = torchvision.models.alexnet(pretrained=True).cuda()\n",
        "\n",
        "# Providing input and output names sets the display names for values\n",
        "# within the model's graph. Setting these does not change the semantics\n",
        "# of the graph; it is only for readability.\n",
        "#\n",
        "# The inputs to the network consist of the flat list of inputs (i.e.\n",
        "# the values you would pass to the forward() method) followed by the\n",
        "# flat list of parameters. You can partially specify names, i.e. provide\n",
        "# a list here shorter than the number of inputs to the model, and we will\n",
        "# only set that subset of names, starting from the beginning.\n",
        "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
        "output_names = [ \"output1\" ]\n",
        "\n",
        "torch.onnx.export(model_ft, input_var, \"/content/model_conv.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph(%actual_input_1 : Float(1, 3, 180, 180, strides=[97200, 32400, 180, 1], requires_grad=0, device=cpu),\n",
            "      %fc.weight : Float(2, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
            "      %fc.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
            "      %193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
            "      %194 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %196 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %197 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %199 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %200 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %202 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %203 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %205 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %206 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
            "      %208 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %209 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %211 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %212 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %214 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %215 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %217 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %218 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %220 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %221 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
            "      %223 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %224 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %226 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %227 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %229 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %230 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %232 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %233 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %235 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %236 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
            "      %238 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %239 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %241 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %242 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %244 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %245 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %247 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %248 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
            "      %250 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %251 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %192 : Float(1, 64, 90, 90, strides=[518400, 8100, 90, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%actual_input_1, %193, %194)\n",
            "  %125 : Float(1, 64, 90, 90, strides=[518400, 8100, 90, 1], requires_grad=1, device=cpu) = onnx::Relu(%192) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %126 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125)\n",
            "  %195 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %196, %197)\n",
            "  %129 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Relu(%195) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %198 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %199, %200)\n",
            "  %132 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Add(%198, %126) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %133 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Relu(%132)\n",
            "  %201 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %202, %203)\n",
            "  %136 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Relu(%201) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %204 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %205, %206)\n",
            "  %139 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Add(%204, %133) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %140 : Float(1, 64, 45, 45, strides=[129600, 2025, 45, 1], requires_grad=1, device=cpu) = onnx::Relu(%139) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %207 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %208, %209)\n",
            "  %143 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Relu(%207) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %210 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %211, %212)\n",
            "  %213 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %214, %215)\n",
            "  %148 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Add(%210, %213) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %149 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Relu(%148)\n",
            "  %216 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %217, %218)\n",
            "  %152 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Relu(%216) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %219 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %220, %221)\n",
            "  %155 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Add(%219, %149) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %156 : Float(1, 128, 23, 23, strides=[67712, 529, 23, 1], requires_grad=1, device=cpu) = onnx::Relu(%155) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %222 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %223, %224)\n",
            "  %159 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Relu(%222) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %225 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %226, %227)\n",
            "  %228 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %229, %230)\n",
            "  %164 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Add(%225, %228) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %165 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Relu(%164)\n",
            "  %231 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %232, %233)\n",
            "  %168 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Relu(%231) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %234 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %235, %236)\n",
            "  %171 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Add(%234, %165) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %172 : Float(1, 256, 12, 12, strides=[36864, 144, 12, 1], requires_grad=1, device=cpu) = onnx::Relu(%171) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %237 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %238, %239)\n",
            "  %175 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Relu(%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %240 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %241, %242)\n",
            "  %243 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %244, %245)\n",
            "  %180 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Add(%240, %243) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %181 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Relu(%180)\n",
            "  %246 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %247, %248)\n",
            "  %184 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Relu(%246) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %249 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %250, %251)\n",
            "  %187 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Add(%249, %181) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:80:0\n",
            "  %188 : Float(1, 512, 6, 6, strides=[18432, 36, 6, 1], requires_grad=1, device=cpu) = onnx::Relu(%187) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1296:0\n",
            "  %189 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%188) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1130:0\n",
            "  %190 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%189) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:243:0\n",
            "  %output1 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%190, %fc.weight, %fc.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1847:0\n",
            "  return (%output1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "xYM1h86fb0xe",
        "outputId": "707cd8da-1cb6-41ce-e63e-10106265f601"
      },
      "source": [
        "import onnx\n",
        "# Load the ONNX model\n",
        "onnx_model_conv = onnx.load(\"/content/model_conv.onnx\")\n",
        "# Check that the IR is well formed\n",
        "onnx.checker.check_model(onnx_model_conv)\n",
        "# Print a human readable representation of the graph\n",
        "onnx.helper.printable_graph(onnx_model_conv.graph)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'graph torch-jit-export (\\n  %actual_input_1[FLOAT, 1x3x180x180]\\n) initializers (\\n  %fc.weight[FLOAT, 2x512]\\n  %fc.bias[FLOAT, 2]\\n  %193[FLOAT, 64x3x7x7]\\n  %194[FLOAT, 64]\\n  %196[FLOAT, 64x64x3x3]\\n  %197[FLOAT, 64]\\n  %199[FLOAT, 64x64x3x3]\\n  %200[FLOAT, 64]\\n  %202[FLOAT, 64x64x3x3]\\n  %203[FLOAT, 64]\\n  %205[FLOAT, 64x64x3x3]\\n  %206[FLOAT, 64]\\n  %208[FLOAT, 128x64x3x3]\\n  %209[FLOAT, 128]\\n  %211[FLOAT, 128x128x3x3]\\n  %212[FLOAT, 128]\\n  %214[FLOAT, 128x64x1x1]\\n  %215[FLOAT, 128]\\n  %217[FLOAT, 128x128x3x3]\\n  %218[FLOAT, 128]\\n  %220[FLOAT, 128x128x3x3]\\n  %221[FLOAT, 128]\\n  %223[FLOAT, 256x128x3x3]\\n  %224[FLOAT, 256]\\n  %226[FLOAT, 256x256x3x3]\\n  %227[FLOAT, 256]\\n  %229[FLOAT, 256x128x1x1]\\n  %230[FLOAT, 256]\\n  %232[FLOAT, 256x256x3x3]\\n  %233[FLOAT, 256]\\n  %235[FLOAT, 256x256x3x3]\\n  %236[FLOAT, 256]\\n  %238[FLOAT, 512x256x3x3]\\n  %239[FLOAT, 512]\\n  %241[FLOAT, 512x512x3x3]\\n  %242[FLOAT, 512]\\n  %244[FLOAT, 512x256x1x1]\\n  %245[FLOAT, 512]\\n  %247[FLOAT, 512x512x3x3]\\n  %248[FLOAT, 512]\\n  %250[FLOAT, 512x512x3x3]\\n  %251[FLOAT, 512]\\n) {\\n  %192 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%actual_input_1, %193, %194)\\n  %125 = Relu(%192)\\n  %126 = MaxPool[kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%125)\\n  %195 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%126, %196, %197)\\n  %129 = Relu(%195)\\n  %198 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%129, %199, %200)\\n  %132 = Add(%198, %126)\\n  %133 = Relu(%132)\\n  %201 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%133, %202, %203)\\n  %136 = Relu(%201)\\n  %204 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%136, %205, %206)\\n  %139 = Add(%204, %133)\\n  %140 = Relu(%139)\\n  %207 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%140, %208, %209)\\n  %143 = Relu(%207)\\n  %210 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%143, %211, %212)\\n  %213 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%140, %214, %215)\\n  %148 = Add(%210, %213)\\n  %149 = Relu(%148)\\n  %216 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%149, %217, %218)\\n  %152 = Relu(%216)\\n  %219 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%152, %220, %221)\\n  %155 = Add(%219, %149)\\n  %156 = Relu(%155)\\n  %222 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%156, %223, %224)\\n  %159 = Relu(%222)\\n  %225 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%159, %226, %227)\\n  %228 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%156, %229, %230)\\n  %164 = Add(%225, %228)\\n  %165 = Relu(%164)\\n  %231 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%165, %232, %233)\\n  %168 = Relu(%231)\\n  %234 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%168, %235, %236)\\n  %171 = Add(%234, %165)\\n  %172 = Relu(%171)\\n  %237 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%172, %238, %239)\\n  %175 = Relu(%237)\\n  %240 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%175, %241, %242)\\n  %243 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%172, %244, %245)\\n  %180 = Add(%240, %243)\\n  %181 = Relu(%180)\\n  %246 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%181, %247, %248)\\n  %184 = Relu(%246)\\n  %249 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%184, %250, %251)\\n  %187 = Add(%249, %181)\\n  %188 = Relu(%187)\\n  %189 = GlobalAveragePool(%188)\\n  %190 = Flatten[axis = 1](%189)\\n  %output1 = Gemm[alpha = 1, beta = 1, transB = 1](%190, %fc.weight, %fc.bias)\\n  return %output1\\n}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnV2x5BcdCix",
        "outputId": "3229d191-2a17-4328-afbd-1140e326b589"
      },
      "source": [
        "!pip install onnx2pytorch"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnx2pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/aa/47c89dd98eb9879600df9f252a4a4ad3cdf89266b4b9ae4bfe77298fa465/onnx2pytorch-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from onnx2pytorch) (1.9.0+cu102)\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from onnx2pytorch) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->onnx2pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.6.0->onnx2pytorch) (57.0.0)\n",
            "Installing collected packages: onnx2pytorch\n",
            "Successfully installed onnx2pytorch-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChmqKm6Zb04G"
      },
      "source": [
        "# ...continuing from above\n",
        "#import onnxruntime as ort\n",
        "#ort_session = ort.InferenceSession('/content/model_conv.onnx')\n",
        "#outputs = ort_session.run(None, {'actual_input_1': np.random.randn(10, 3, 224, 224).astype(np.float32)})\n",
        "\n",
        "#print(outputs[0])\n",
        "from onnx2pytorch import ConvertModel\n",
        "\n",
        "#onnx_model = onnx.load(path_to_onnx_model)\n",
        "pytorch_model = ConvertModel(onnx_model_conv)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-LVxc9Tb09A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_HX6YKpb1Bc",
        "outputId": "3555968e-997c-4274-83d4-e773a34c916f"
      },
      "source": [
        "tf_rep = prepare(onnx_model_conv)  # prepare tf representation\n",
        "tf_rep.export_graph('/content/onnx_model_conv.pb')  # export the model\n",
        "\n",
        "tf_rep.inputs"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/onnx_model_conv.pb/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/onnx_model_conv.pb/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['actual_input_1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0H3p788b1GJ",
        "outputId": "25a0bde9-3adf-4c80-9c15-02228ee96734"
      },
      "source": [
        "import onnx\n",
        "from onnx2keras import onnx_to_keras\n",
        "# Call the converter (input - is the main model input name, can be different for your model)\n",
        "k_model = onnx_to_keras(onnx_model_conv, ['actual_input_1'])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:None\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> actual_input_1.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> output1.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight fc.weight with shape (2, 512).\n",
            "DEBUG:onnx2keras:Found weight fc.bias with shape (2,).\n",
            "DEBUG:onnx2keras:Found weight 193 with shape (64, 3, 7, 7).\n",
            "DEBUG:onnx2keras:Found weight 194 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 196 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 197 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 199 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 200 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 202 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 203 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 205 with shape (64, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 206 with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight 208 with shape (128, 64, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 209 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 211 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 212 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 214 with shape (128, 64, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 215 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 217 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 218 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 220 with shape (128, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 221 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight 223 with shape (256, 128, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 224 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 226 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 227 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 229 with shape (256, 128, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 230 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 232 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 233 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 235 with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 236 with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight 238 with shape (512, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 239 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 241 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 242 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 244 with shape (512, 256, 1, 1).\n",
            "DEBUG:onnx2keras:Found weight 245 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 247 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 248 with shape (512,).\n",
            "DEBUG:onnx2keras:Found weight 250 with shape (512, 512, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight 251 with shape (512,).\n",
            "DEBUG:onnx2keras:Found input actual_input_1 with shape [3, 180, 180]\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 192\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [7, 7], 'pads': [3, 3, 3, 3], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name actual_input_1).\n",
            "DEBUG:onnx2keras:Check input 1 (name 193).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 194).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 90, 90), dtype=tf.float32, name=None), name='192/BiasAdd:0', description=\"created by layer '192'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 125\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 192).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 90, 90), dtype=tf.float32, name=None), name='125/Relu:0', description=\"created by layer '125'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 126\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 125).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='126/MaxPool:0', description=\"created by layer '126'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 195\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 126).\n",
            "DEBUG:onnx2keras:Check input 1 (name 196).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 197).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='195/BiasAdd:0', description=\"created by layer '195'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 129\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 195).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='129/Relu:0', description=\"created by layer '129'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 198\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 129).\n",
            "DEBUG:onnx2keras:Check input 1 (name 199).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 200).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='198/BiasAdd:0', description=\"created by layer '198'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 132\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 198).\n",
            "DEBUG:onnx2keras:Check input 1 (name 126).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='132/add:0', description=\"created by layer '132'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 133\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 132).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='133/Relu:0', description=\"created by layer '133'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 201\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 133).\n",
            "DEBUG:onnx2keras:Check input 1 (name 202).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 203).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='201/BiasAdd:0', description=\"created by layer '201'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 136\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 201).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='136/Relu:0', description=\"created by layer '136'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 204\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 136).\n",
            "DEBUG:onnx2keras:Check input 1 (name 205).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 206).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='204/BiasAdd:0', description=\"created by layer '204'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 139\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 204).\n",
            "DEBUG:onnx2keras:Check input 1 (name 133).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='139/add:0', description=\"created by layer '139'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 140\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 139).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 64, 45, 45), dtype=tf.float32, name=None), name='140/Relu:0', description=\"created by layer '140'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 207\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 140).\n",
            "DEBUG:onnx2keras:Check input 1 (name 208).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 209).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='207/BiasAdd:0', description=\"created by layer '207'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 143\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 207).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='143/Relu:0', description=\"created by layer '143'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 210\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 143).\n",
            "DEBUG:onnx2keras:Check input 1 (name 211).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 212).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='210/BiasAdd:0', description=\"created by layer '210'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 213\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 140).\n",
            "DEBUG:onnx2keras:Check input 1 (name 214).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 215).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='213/BiasAdd:0', description=\"created by layer '213'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 148\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 210).\n",
            "DEBUG:onnx2keras:Check input 1 (name 213).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='148/add:0', description=\"created by layer '148'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 149\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 148).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='149/Relu:0', description=\"created by layer '149'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 216\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 149).\n",
            "DEBUG:onnx2keras:Check input 1 (name 217).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 218).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='216/BiasAdd:0', description=\"created by layer '216'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 152\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 216).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='152/Relu:0', description=\"created by layer '152'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 219\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 152).\n",
            "DEBUG:onnx2keras:Check input 1 (name 220).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 221).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='219/BiasAdd:0', description=\"created by layer '219'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 155\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 219).\n",
            "DEBUG:onnx2keras:Check input 1 (name 149).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='155/add:0', description=\"created by layer '155'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 156\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 155).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 128, 23, 23), dtype=tf.float32, name=None), name='156/Relu:0', description=\"created by layer '156'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 222\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 156).\n",
            "DEBUG:onnx2keras:Check input 1 (name 223).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 224).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='222/BiasAdd:0', description=\"created by layer '222'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 159\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 222).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='159/Relu:0', description=\"created by layer '159'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 225\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 159).\n",
            "DEBUG:onnx2keras:Check input 1 (name 226).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 227).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='225/BiasAdd:0', description=\"created by layer '225'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 228\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 156).\n",
            "DEBUG:onnx2keras:Check input 1 (name 229).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 230).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='228/BiasAdd:0', description=\"created by layer '228'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 164\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 225).\n",
            "DEBUG:onnx2keras:Check input 1 (name 228).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='164/add:0', description=\"created by layer '164'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 165\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 164).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='165/Relu:0', description=\"created by layer '165'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 231\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 165).\n",
            "DEBUG:onnx2keras:Check input 1 (name 232).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 233).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='231/BiasAdd:0', description=\"created by layer '231'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 168\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 231).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='168/Relu:0', description=\"created by layer '168'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 234\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 168).\n",
            "DEBUG:onnx2keras:Check input 1 (name 235).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 236).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='234/BiasAdd:0', description=\"created by layer '234'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 171\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 234).\n",
            "DEBUG:onnx2keras:Check input 1 (name 165).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='171/add:0', description=\"created by layer '171'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 172\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 171).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 256, 12, 12), dtype=tf.float32, name=None), name='172/Relu:0', description=\"created by layer '172'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 237\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 172).\n",
            "DEBUG:onnx2keras:Check input 1 (name 238).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 239).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='237/BiasAdd:0', description=\"created by layer '237'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 175\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 237).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='175/Relu:0', description=\"created by layer '175'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 240\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 175).\n",
            "DEBUG:onnx2keras:Check input 1 (name 241).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 242).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='240/BiasAdd:0', description=\"created by layer '240'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 243\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 172).\n",
            "DEBUG:onnx2keras:Check input 1 (name 244).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 245).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='243/BiasAdd:0', description=\"created by layer '243'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 180\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 240).\n",
            "DEBUG:onnx2keras:Check input 1 (name 243).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='180/add:0', description=\"created by layer '180'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 181\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 180).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='181/Relu:0', description=\"created by layer '181'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 246\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 181).\n",
            "DEBUG:onnx2keras:Check input 1 (name 247).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 248).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='246/BiasAdd:0', description=\"created by layer '246'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 184\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 246).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='184/Relu:0', description=\"created by layer '184'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 249\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 184).\n",
            "DEBUG:onnx2keras:Check input 1 (name 250).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name 251).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='249/BiasAdd:0', description=\"created by layer '249'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Add\n",
            "DEBUG:onnx2keras:node_name: 187\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 249).\n",
            "DEBUG:onnx2keras:Check input 1 (name 181).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:add:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='187/add:0', description=\"created by layer '187'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 188\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 187).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 6, 6), dtype=tf.float32, name=None), name='188/Relu:0', description=\"created by layer '188'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: GlobalAveragePool\n",
            "DEBUG:onnx2keras:node_name: 189\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 188).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:global_avg_pool:Now expand dimensions twice.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512, 1, 1), dtype=tf.float32, name=None), name='189_EXPAND2/ExpandDims:0', description=\"created by layer '189_EXPAND2'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Flatten\n",
            "DEBUG:onnx2keras:node_name: 190\n",
            "DEBUG:onnx2keras:node_params: {'axis': 1, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 189).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:flatten:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='190/Reshape:0', description=\"created by layer '190'\")\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: output1\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 190).\n",
            "DEBUG:onnx2keras:Check input 1 (name fc.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name fc.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 512, output units 2.\n",
            "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='output1/BiasAdd:0', description=\"created by layer 'output1'\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDAiSCT_b1LZ",
        "outputId": "5880bfda-9fd4-4e1b-9701-65599146073e"
      },
      "source": [
        "k_model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "actual_input_1 (InputLayer)     [(None, 3, 180, 180) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "192_pad (ZeroPadding2D)         (None, 3, 186, 186)  0           actual_input_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "192 (Conv2D)                    (None, 64, 90, 90)   9472        192_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "125 (Activation)                (None, 64, 90, 90)   0           192[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "126_pad (ZeroPadding2D)         (None, 64, 92, 92)   0           125[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "126 (MaxPooling2D)              (None, 64, 45, 45)   0           126_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "195_pad (ZeroPadding2D)         (None, 64, 47, 47)   0           126[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "195 (Conv2D)                    (None, 64, 45, 45)   36928       195_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "129 (Activation)                (None, 64, 45, 45)   0           195[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "198_pad (ZeroPadding2D)         (None, 64, 47, 47)   0           129[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "198 (Conv2D)                    (None, 64, 45, 45)   36928       198_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "132 (Add)                       (None, 64, 45, 45)   0           198[0][0]                        \n",
            "                                                                 126[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "133 (Activation)                (None, 64, 45, 45)   0           132[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "201_pad (ZeroPadding2D)         (None, 64, 47, 47)   0           133[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "201 (Conv2D)                    (None, 64, 45, 45)   36928       201_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "136 (Activation)                (None, 64, 45, 45)   0           201[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "204_pad (ZeroPadding2D)         (None, 64, 47, 47)   0           136[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "204 (Conv2D)                    (None, 64, 45, 45)   36928       204_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "139 (Add)                       (None, 64, 45, 45)   0           204[0][0]                        \n",
            "                                                                 133[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "140 (Activation)                (None, 64, 45, 45)   0           139[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "207_pad (ZeroPadding2D)         (None, 64, 47, 47)   0           140[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "207 (Conv2D)                    (None, 128, 23, 23)  73856       207_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "143 (Activation)                (None, 128, 23, 23)  0           207[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "210_pad (ZeroPadding2D)         (None, 128, 25, 25)  0           143[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "210 (Conv2D)                    (None, 128, 23, 23)  147584      210_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "213 (Conv2D)                    (None, 128, 23, 23)  8320        140[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "148 (Add)                       (None, 128, 23, 23)  0           210[0][0]                        \n",
            "                                                                 213[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "149 (Activation)                (None, 128, 23, 23)  0           148[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "216_pad (ZeroPadding2D)         (None, 128, 25, 25)  0           149[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "216 (Conv2D)                    (None, 128, 23, 23)  147584      216_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "152 (Activation)                (None, 128, 23, 23)  0           216[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "219_pad (ZeroPadding2D)         (None, 128, 25, 25)  0           152[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "219 (Conv2D)                    (None, 128, 23, 23)  147584      219_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "155 (Add)                       (None, 128, 23, 23)  0           219[0][0]                        \n",
            "                                                                 149[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "156 (Activation)                (None, 128, 23, 23)  0           155[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "222_pad (ZeroPadding2D)         (None, 128, 25, 25)  0           156[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "222 (Conv2D)                    (None, 256, 12, 12)  295168      222_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "159 (Activation)                (None, 256, 12, 12)  0           222[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "225_pad (ZeroPadding2D)         (None, 256, 14, 14)  0           159[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "225 (Conv2D)                    (None, 256, 12, 12)  590080      225_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "228 (Conv2D)                    (None, 256, 12, 12)  33024       156[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "164 (Add)                       (None, 256, 12, 12)  0           225[0][0]                        \n",
            "                                                                 228[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "165 (Activation)                (None, 256, 12, 12)  0           164[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "231_pad (ZeroPadding2D)         (None, 256, 14, 14)  0           165[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "231 (Conv2D)                    (None, 256, 12, 12)  590080      231_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "168 (Activation)                (None, 256, 12, 12)  0           231[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "234_pad (ZeroPadding2D)         (None, 256, 14, 14)  0           168[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "234 (Conv2D)                    (None, 256, 12, 12)  590080      234_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "171 (Add)                       (None, 256, 12, 12)  0           234[0][0]                        \n",
            "                                                                 165[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "172 (Activation)                (None, 256, 12, 12)  0           171[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "237_pad (ZeroPadding2D)         (None, 256, 14, 14)  0           172[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "237 (Conv2D)                    (None, 512, 6, 6)    1180160     237_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "175 (Activation)                (None, 512, 6, 6)    0           237[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "240_pad (ZeroPadding2D)         (None, 512, 8, 8)    0           175[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "240 (Conv2D)                    (None, 512, 6, 6)    2359808     240_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "243 (Conv2D)                    (None, 512, 6, 6)    131584      172[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "180 (Add)                       (None, 512, 6, 6)    0           240[0][0]                        \n",
            "                                                                 243[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "181 (Activation)                (None, 512, 6, 6)    0           180[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "246_pad (ZeroPadding2D)         (None, 512, 8, 8)    0           181[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "246 (Conv2D)                    (None, 512, 6, 6)    2359808     246_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "184 (Activation)                (None, 512, 6, 6)    0           246[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "249_pad (ZeroPadding2D)         (None, 512, 8, 8)    0           184[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "249 (Conv2D)                    (None, 512, 6, 6)    2359808     249_pad[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "187 (Add)                       (None, 512, 6, 6)    0           249[0][0]                        \n",
            "                                                                 181[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "188 (Activation)                (None, 512, 6, 6)    0           187[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "189 (GlobalAveragePooling2D)    (None, 512)          0           188[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "189_EXPAND1 (Lambda)            (None, 512, 1)       0           189[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "189_EXPAND2 (Lambda)            (None, 512, 1, 1)    0           189_EXPAND1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "190 (Reshape)                   (None, 512)          0           189_EXPAND2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 2)            1026        190[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 11,172,738\n",
            "Trainable params: 11,172,738\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMRscOHqwlZ"
      },
      "source": [
        "#tf.shape(tf_tensor_images_train)\n",
        "\n",
        "#tf_tensor_images_train2 = tf.reshape(tf_tensor_images_train,(28, 28, 1))\n",
        "#tf_tensor_images_train#"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaJr74nSoS_7"
      },
      "source": [
        "k_model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "lUgobilpoTFO",
        "outputId": "199803c2-21a0-45c4-8c38-85600f78777b"
      },
      "source": [
        "fit_history_k_model_model_conv = k_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=5\n",
        ")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-cf5d277dc7a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:270 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_6: expected shape=(None, 3, 180, 180), found shape=(None, 180, 180, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhgIrqyEoTUb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMw8AXScoTZZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v143UN9hjpMZ",
        "outputId": "8e4801e5-7d98-4ba4-b5e0-32a9e82a19c2"
      },
      "source": [
        "k_model.save(\"/content/model_conv_keras.h5\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 3\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi3VJ3A8b1OF"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI4eew3_b1SJ",
        "outputId": "3a6f5703-fcc8-4d9a-a73b-d862b041b37c"
      },
      "source": [
        "#summary(pytorch_model, (3, 180, 180))\n",
        "torch.save(model_conv, '/content/model_conv.pt')\n",
        "\n",
        "summary(model_conv, (3, 180, 180), batch_size=1, device='cpu')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [1, 64, 90, 90]           9,408\n",
            "       BatchNorm2d-2            [1, 64, 90, 90]             128\n",
            "              ReLU-3            [1, 64, 90, 90]               0\n",
            "         MaxPool2d-4            [1, 64, 45, 45]               0\n",
            "            Conv2d-5            [1, 64, 45, 45]          36,864\n",
            "       BatchNorm2d-6            [1, 64, 45, 45]             128\n",
            "              ReLU-7            [1, 64, 45, 45]               0\n",
            "            Conv2d-8            [1, 64, 45, 45]          36,864\n",
            "       BatchNorm2d-9            [1, 64, 45, 45]             128\n",
            "             ReLU-10            [1, 64, 45, 45]               0\n",
            "       BasicBlock-11            [1, 64, 45, 45]               0\n",
            "           Conv2d-12            [1, 64, 45, 45]          36,864\n",
            "      BatchNorm2d-13            [1, 64, 45, 45]             128\n",
            "             ReLU-14            [1, 64, 45, 45]               0\n",
            "           Conv2d-15            [1, 64, 45, 45]          36,864\n",
            "      BatchNorm2d-16            [1, 64, 45, 45]             128\n",
            "             ReLU-17            [1, 64, 45, 45]               0\n",
            "       BasicBlock-18            [1, 64, 45, 45]               0\n",
            "           Conv2d-19           [1, 128, 23, 23]          73,728\n",
            "      BatchNorm2d-20           [1, 128, 23, 23]             256\n",
            "             ReLU-21           [1, 128, 23, 23]               0\n",
            "           Conv2d-22           [1, 128, 23, 23]         147,456\n",
            "      BatchNorm2d-23           [1, 128, 23, 23]             256\n",
            "           Conv2d-24           [1, 128, 23, 23]           8,192\n",
            "      BatchNorm2d-25           [1, 128, 23, 23]             256\n",
            "             ReLU-26           [1, 128, 23, 23]               0\n",
            "       BasicBlock-27           [1, 128, 23, 23]               0\n",
            "           Conv2d-28           [1, 128, 23, 23]         147,456\n",
            "      BatchNorm2d-29           [1, 128, 23, 23]             256\n",
            "             ReLU-30           [1, 128, 23, 23]               0\n",
            "           Conv2d-31           [1, 128, 23, 23]         147,456\n",
            "      BatchNorm2d-32           [1, 128, 23, 23]             256\n",
            "             ReLU-33           [1, 128, 23, 23]               0\n",
            "       BasicBlock-34           [1, 128, 23, 23]               0\n",
            "           Conv2d-35           [1, 256, 12, 12]         294,912\n",
            "      BatchNorm2d-36           [1, 256, 12, 12]             512\n",
            "             ReLU-37           [1, 256, 12, 12]               0\n",
            "           Conv2d-38           [1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-39           [1, 256, 12, 12]             512\n",
            "           Conv2d-40           [1, 256, 12, 12]          32,768\n",
            "      BatchNorm2d-41           [1, 256, 12, 12]             512\n",
            "             ReLU-42           [1, 256, 12, 12]               0\n",
            "       BasicBlock-43           [1, 256, 12, 12]               0\n",
            "           Conv2d-44           [1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-45           [1, 256, 12, 12]             512\n",
            "             ReLU-46           [1, 256, 12, 12]               0\n",
            "           Conv2d-47           [1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-48           [1, 256, 12, 12]             512\n",
            "             ReLU-49           [1, 256, 12, 12]               0\n",
            "       BasicBlock-50           [1, 256, 12, 12]               0\n",
            "           Conv2d-51             [1, 512, 6, 6]       1,179,648\n",
            "      BatchNorm2d-52             [1, 512, 6, 6]           1,024\n",
            "             ReLU-53             [1, 512, 6, 6]               0\n",
            "           Conv2d-54             [1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-55             [1, 512, 6, 6]           1,024\n",
            "           Conv2d-56             [1, 512, 6, 6]         131,072\n",
            "      BatchNorm2d-57             [1, 512, 6, 6]           1,024\n",
            "             ReLU-58             [1, 512, 6, 6]               0\n",
            "       BasicBlock-59             [1, 512, 6, 6]               0\n",
            "           Conv2d-60             [1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-61             [1, 512, 6, 6]           1,024\n",
            "             ReLU-62             [1, 512, 6, 6]               0\n",
            "           Conv2d-63             [1, 512, 6, 6]       2,359,296\n",
            "      BatchNorm2d-64             [1, 512, 6, 6]           1,024\n",
            "             ReLU-65             [1, 512, 6, 6]               0\n",
            "       BasicBlock-66             [1, 512, 6, 6]               0\n",
            "AdaptiveAvgPool2d-67             [1, 512, 1, 1]               0\n",
            "           Linear-68                     [1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 11,176,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.37\n",
            "Forward/backward pass size (MB): 41.72\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 84.73\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}